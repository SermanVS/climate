{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import copy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from config_reader import Config\n",
    "from read_data import read_data\n",
    "from preproc_data import *\n",
    "from label_data import label_data\n",
    "from split_data import split_data\n",
    "from detection import *\n",
    "\n",
    "cfg = Config()\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone_events, data = read_data(path='../data')\n",
    "# Consider renaming first variable\n",
    "cyclone_events_data, data, metrics = preproc_data(cyclone_events, metrics=data)\n",
    "labels, events = label_data(cyclone_events_data.ce2)\n",
    "train_data, test_data, labels_train, labels_test, train_id, test_id = split_data(data, labels, ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train_old = labels_train\n",
    "labels_train = [[item, 1 - item] for item in labels_train]\n",
    "labels_test = [[item, 1 - item] for item in labels_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = \"DenseNet121\"\n",
    "filename = \"DenseNet121.ipynb\"\n",
    "network_name = filename.split('.')[0]\n",
    "comment = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from show_test_data import show_test_data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from config_reader import Config\n",
    "from sigma import sigma\n",
    "import pandas as pd\n",
    "\n",
    "def get_start_ticks(labels_test):\n",
    "    labels_test = np.array(labels_test)\n",
    "    start_ticks = []\n",
    "    for i in range(len(labels_test) - 1):\n",
    "        if (labels_test[i] == 0 and labels_test[i+1] == 1):\n",
    "            start_ticks.append(i+1)\n",
    "    return np.array(start_ticks)\n",
    "\n",
    "def predicted_event_id(tick, start_ticks):\n",
    "    idx = (np.abs(start_ticks - tick)).argmin()\n",
    "    return idx\n",
    "\n",
    "def fill_preicted_events(predicted_events, start_ticks, labels_test):\n",
    "    cfg = Config()\n",
    "    #res = np.zeros(shape=len(labels_test), dtype=int)\n",
    "    res = [0] * len(labels_test)\n",
    "    for k, pr in enumerate(predicted_events):\n",
    "        if pr == 1:\n",
    "            for i in range(start_ticks[k], start_ticks[k] + cfg.w):\n",
    "                res[i] = 1\n",
    "\n",
    "    res = indices(res, 1)\n",
    "    return np.array(res, dtype=int)\n",
    "\n",
    "def indices(lst, item):\n",
    "    return [i for i, x in enumerate(lst) if x == item]\n",
    "\n",
    "\n",
    "def test(nn, test_data, labels_test):\n",
    "    # Test the model\n",
    "    cfg = Config()\n",
    "    nn.eval()    \n",
    "    sigmas = []\n",
    "    tp_ids = []\n",
    "    fp_ids = []\n",
    "    fn_ids = []\n",
    "    tn_ids = []\n",
    "\n",
    "    if cfg.mode == 'predict':\n",
    "        predicted = np.zeros(shape=test_data.shape[2])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        tn = 0\n",
    "        for i in range(test_data.shape[2]):\n",
    "            if (labels_test[i] == 2):\n",
    "                continue\n",
    "            image = test_data[:, :, i]\n",
    "            label = labels_test[i]\n",
    "            \n",
    "            image = image.unsqueeze(0) \n",
    "            image = image.unsqueeze(0) \n",
    "            \n",
    "            test_output = nn(image)\n",
    "            #arg = test_output.item()\n",
    "            #sig = sigma(arg)\n",
    "            #sigmas.append(sig)\n",
    "            \n",
    "            _, pred_y = torch.max(test_output.data, 1)\n",
    "            # print(f\"pred_y {pred_y}\")\n",
    "            # print(f\"label {label}\")\n",
    "            #print(sig)\n",
    "            # 0 - 1 when cyclone is present\n",
    "            if (pred_y == label and label == 1):\n",
    "                tp += 1\n",
    "                tp_ids.append(i)\n",
    "            # 1 - 0 when no cyclone is present\n",
    "            elif (pred_y == label and label == 0):\n",
    "                tn += 1\n",
    "                tn_ids.append(i)\n",
    "            # 0 - 1 when no cyclone is present\n",
    "            elif (pred_y != label and label == 1):\n",
    "                fn += 1\n",
    "                fn_ids.append(i)\n",
    "            # 1 - 0 when cyclone is present\n",
    "            elif (pred_y != label and label == 0):\n",
    "                fp += 1\n",
    "                fp_ids.append(i)\n",
    "            pass   \n",
    "        pass\n",
    "    \n",
    "    if cfg.mode == 'predict':\n",
    "        predicted[tp_ids] = 1\n",
    "        event_start_ticks = get_start_ticks(labels_test)\n",
    "        predicted_events = np.zeros(shape=len(event_start_ticks))\n",
    "\n",
    "        for item in tp_ids:\n",
    "            predicted_event = predicted_event_id(item, event_start_ticks)\n",
    "            predicted_events[predicted_event] = 1\n",
    "\n",
    "        tp_ids = fill_preicted_events(predicted_events, event_start_ticks, labels_test)\n",
    "\n",
    "        tp = predicted_events.sum()\n",
    "        fn = len(event_start_ticks) - tp\n",
    "    \n",
    "        fp = fp // cfg.w\n",
    "        tn = tn // cfg.w\n",
    "    return tp, tn, fp, fn, sigmas, (tp_ids, fp_ids, fn_ids, tn_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from show_loss import show_loss\n",
    "from get_test_stats import get_test_stats\n",
    "from show_test_data import show_test_data\n",
    "from sklearn import metrics\n",
    "from parameters import Stats\n",
    "from IPython.display import clear_output\n",
    "from config_reader import Config\n",
    "\n",
    "'''\n",
    "Train the network on given data.\n",
    "\n",
    "nn           - Network to train.\n",
    "batch_size   - Batch size to apply to data.\n",
    "num_epochs   - How many epochs to train for.\n",
    "train_data   - Data to train on.\n",
    "labels_train - Labels for train_data.\n",
    "loss_func    - Loss function.\n",
    "optimizer    - Optimizer for gradients.\n",
    "draw         - Whether to display loss dynamics.\n",
    "step_test    - Whether to test on test data after each epoch.\n",
    "args         - test data and test labels.\n",
    "\n",
    "It's not recommended to use 'draw' and 'step_test' at the same time.\n",
    "'''\n",
    "def train(cnn, batch_size, num_epochs, train_data, labels_train_pre, loss_func, optimizer, args, draw=False, step_test=False, preload=False):\n",
    "    if preload:\n",
    "        try:\n",
    "            cnn = models.resnet18(pretrained=False) \n",
    "            cnn.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "            cnn.fc = nn.Linear(in_features=512, out_features=2, bias=True)\n",
    "            cnn.load_state_dict(torch.load(\"resnet18_full.pt\"))\n",
    "        except:\n",
    "            cnn = models.resnet18(pretrained=False) \n",
    "            cnn.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "            cnn.fc = nn.Linear(in_features=512, out_features=2, bias=True) \n",
    "    cnn.train()\n",
    "    cnn = cnn.double()\n",
    "    loss_vals = []\n",
    "    epoch_loss = []\n",
    "\n",
    "    labels_train = torch.tensor([(0 if i == 2 else i) for i in labels_train_pre])\n",
    "    \n",
    "    test_stats_list = []\n",
    "    train_stats_list = []\n",
    "\n",
    "    tprs_test = []\n",
    "    fprs_test = []\n",
    "    tprs_train  = []\n",
    "    fprs_train = []\n",
    "\n",
    "    fprs_test.append(0)\n",
    "    tprs_test.append(0)\n",
    "    fprs_train.append(0)\n",
    "    tprs_train.append(0)\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        running_loss = 0.0\n",
    "        iters = int(train_data.shape[2] / batch_size)\n",
    "        for i in range(iters):\n",
    "            images = train_data[:, :, i:i + batch_size]\n",
    "            labels = labels_train[i:i + batch_size]        \n",
    "            \n",
    "            b_x = images  \n",
    "            # Change to Double if doesn't work\n",
    "            b_y = labels.double()\n",
    "            b_x = b_x.reshape((batch_size, 1, 36, 69))          \n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            output = cnn(b_x)\n",
    "            #print(output)\n",
    "            loss = loss_func(input=output, target=b_y)   \n",
    "            epoch_loss.append(loss.item())\n",
    "            running_loss += loss.item() * batch_size\n",
    "            if (draw == True and i != 0 and i % 100 == 0 and not step_test):\n",
    "                show_loss(epoch_loss, loss_vals)\n",
    "            elif (draw and i != 0 and i % 100 == 0 and step_test and epoch > 0):\n",
    "                show_loss(epoch_loss, loss_vals, clear_after=False)\n",
    "                show_test_data(test_stats_list, train_stats_list)\n",
    "                clear_output(True)\n",
    "            elif (draw and i != 0 and i % 100 == 0 and step_test and epoch == 0):\n",
    "                show_loss(epoch_loss, loss_vals)\n",
    "            \n",
    "            loss.backward()                           \n",
    "            optimizer.step()  \n",
    "\n",
    "        if (step_test):\n",
    "            tp, tn, fp, fn, sigmas, _ = test(cnn, args[0], args[1])  \n",
    "            test_stats = get_test_stats(args[0].shape[2], tp, tn, fp, fn, sigmas)          \n",
    "            test_stats_list.append(test_stats)          \n",
    "\n",
    "            tp, tn, fp, fn, sigmas, _ = test(cnn, train_data, labels_train_pre)  \n",
    "            train_stats = get_test_stats(args[0].shape[2], tp, tn, fp, fn, sigmas)       \n",
    "            train_stats_list.append(train_stats)\n",
    "\n",
    "            show_test_data(test_stats_list, train_stats_list)\n",
    "            cnn.train()\n",
    "        pass\n",
    "        torch.save(cnn, \"resnet18_full.pt\")\n",
    "        loss_vals.append(running_loss / train_data.shape[2])\n",
    "        \n",
    "    tprs_test += [item.tpr for item in test_stats_list]\n",
    "    tprs_train += [item.tpr for item in train_stats_list]\n",
    "    fprs_test += [item.fpr for item in test_stats_list]\n",
    "    fprs_train += [item.fpr for item in train_stats_list]\n",
    "\n",
    "    fprs_test.append(1)\n",
    "    tprs_test.append(1)\n",
    "    fprs_train.append(1)\n",
    "    tprs_train.append(1)\n",
    "\n",
    "    fprs_test, tprs_test = zip(*sorted(zip(fprs_test, tprs_test)))\n",
    "    fprs_train, tprs_train = zip(*sorted(zip(fprs_train, tprs_train)))\n",
    "\n",
    "    # sort by fpr\n",
    "    auc_test = metrics.auc(fprs_test, tprs_test)\n",
    "    auc_train = metrics.auc(fprs_train, tprs_train)\n",
    "    return auc_test, auc_train \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "batch_size = 24\n",
    "\n",
    "\n",
    "y = torch.tensor(list(labels_train_old))\n",
    "class_weights=class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y.numpy())\n",
    "class_weights=torch.tensor(class_weights, dtype=torch.double)\n",
    "\n",
    "cnn = models.resnet18(pretrained=True)\n",
    "cnn.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "cnn.fc = nn.Linear(in_features=512, out_features=2, bias=True)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights[1]/class_weights[0], reduction='mean') \n",
    "\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f3cd1305c3541108bd9a0e229a362f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mh:\\Lobachevsky\\Climate\\src\\ResNet18.ipynb Cell 8\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/h%3A/Lobachevsky/Climate/src/ResNet18.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m auc_test, auc_train \u001b[39m=\u001b[39m train(cnn\u001b[39m=\u001b[39;49mcnn, batch_size\u001b[39m=\u001b[39;49mbatch_size, num_epochs\u001b[39m=\u001b[39;49mnum_epochs, train_data\u001b[39m=\u001b[39;49mtrain_data, labels_train_pre\u001b[39m=\u001b[39;49mlabels_train, loss_func\u001b[39m=\u001b[39;49mcriterion, optimizer\u001b[39m=\u001b[39;49moptimizer, args\u001b[39m=\u001b[39;49m(test_data, labels_test), draw\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, step_test\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, preload\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;32mh:\\Lobachevsky\\Climate\\src\\ResNet18.ipynb Cell 8\u001b[0m in \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Lobachevsky/Climate/src/ResNet18.ipynb#X10sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m b_x \u001b[39m=\u001b[39m b_x\u001b[39m.\u001b[39mreshape((batch_size, \u001b[39m1\u001b[39m, \u001b[39m36\u001b[39m, \u001b[39m69\u001b[39m))          \n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Lobachevsky/Climate/src/ResNet18.ipynb#X10sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/h%3A/Lobachevsky/Climate/src/ResNet18.ipynb#X10sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m output \u001b[39m=\u001b[39m cnn(b_x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Lobachevsky/Climate/src/ResNet18.ipynb#X10sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39m#print(output)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Lobachevsky/Climate/src/ResNet18.ipynb#X10sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_func(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39moutput, target\u001b[39m=\u001b[39mb_y)   \n",
      "File \u001b[1;32mg:\\Anaconda3\\envs\\mlunn2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mg:\\Anaconda3\\envs\\mlunn2\\lib\\site-packages\\torchvision\\models\\resnet.py:249\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 249\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[1;32mg:\\Anaconda3\\envs\\mlunn2\\lib\\site-packages\\torchvision\\models\\resnet.py:240\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    238\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(x)\n\u001b[0;32m    239\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer3(x)\n\u001b[1;32m--> 240\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer4(x)\n\u001b[0;32m    242\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[0;32m    243\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mg:\\Anaconda3\\envs\\mlunn2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mg:\\Anaconda3\\envs\\mlunn2\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mg:\\Anaconda3\\envs\\mlunn2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mg:\\Anaconda3\\envs\\mlunn2\\lib\\site-packages\\torchvision\\models\\resnet.py:70\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m     68\u001b[0m     identity \u001b[39m=\u001b[39m x\n\u001b[1;32m---> 70\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[0;32m     71\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(out)\n\u001b[0;32m     72\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n",
      "File \u001b[1;32mg:\\Anaconda3\\envs\\mlunn2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mg:\\Anaconda3\\envs\\mlunn2\\lib\\site-packages\\torch\\nn\\modules\\conv.py:446\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 446\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mg:\\Anaconda3\\envs\\mlunn2\\lib\\site-packages\\torch\\nn\\modules\\conv.py:442\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    440\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    441\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 442\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    443\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "auc_test, auc_train = train(cnn=cnn, batch_size=batch_size, num_epochs=num_epochs, train_data=train_data, labels_train_pre=labels_train, loss_func=criterion, optimizer=optimizer, args=(test_data, labels_test), draw=True, step_test=False, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlunn2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7906f88924d0acbcc878920ce9dbcc77a020e1b0135b8245f9ac081820afa623"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
