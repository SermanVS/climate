{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_final_table import make_final_table\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Description</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Hyperparameters</th>\n",
       "      <th>Resulting_hyperparameters</th>\n",
       "      <th>BA_train</th>\n",
       "      <th>BA_test</th>\n",
       "      <th>F1_train</th>\n",
       "      <th>F1_test</th>\n",
       "      <th>G_train</th>\n",
       "      <th>G_test</th>\n",
       "      <th>I_train</th>\n",
       "      <th>I_test</th>\n",
       "      <th>fpr_train</th>\n",
       "      <th>fpr_test</th>\n",
       "      <th>tpr_train</th>\n",
       "      <th>tpr_test</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_test</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>First network (10 epochs) with following layer...</td>\n",
       "      <td>Cyclone.ipynb</td>\n",
       "      <td>(12, 0.5, 1.0, 50.0, 2.0)</td>\n",
       "      <td>[0.08904803785546497, 1.3161153018450304, 50.2...</td>\n",
       "      <td>0.619279</td>\n",
       "      <td>0.615872</td>\n",
       "      <td>0.369937</td>\n",
       "      <td>0.36192</td>\n",
       "      <td>7008.685517</td>\n",
       "      <td>1697.523861</td>\n",
       "      <td>0.038438</td>\n",
       "      <td>0.037243</td>\n",
       "      <td>0.00793</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>0.246488</td>\n",
       "      <td>0.239459</td>\n",
       "      <td>0.619309</td>\n",
       "      <td>0.615954</td>\n",
       "      <td>Pretty nice.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Same network, doubled the batch_size.</td>\n",
       "      <td>Cyclone_bs24.ipynb</td>\n",
       "      <td>(24, 0.5, 1.0, 50.0, 2.0)</td>\n",
       "      <td>[0.12595123010387912, 1.3041119290093375, 50.2...</td>\n",
       "      <td>0.619279</td>\n",
       "      <td>0.615872</td>\n",
       "      <td>0.369937</td>\n",
       "      <td>0.36192</td>\n",
       "      <td>7008.685517</td>\n",
       "      <td>1697.523861</td>\n",
       "      <td>0.038438</td>\n",
       "      <td>0.037243</td>\n",
       "      <td>0.00793</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>0.246488</td>\n",
       "      <td>0.239459</td>\n",
       "      <td>0.696043</td>\n",
       "      <td>0.700299</td>\n",
       "      <td>Surprised statistics are unchanged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Decreased amount of weights. w*b = d, a*b = e....</td>\n",
       "      <td>Cyclone_bs24_de.ipynb</td>\n",
       "      <td>(24, 25.0, 50.0, 2.0)</td>\n",
       "      <td>[12.55361778953873, 62.36485336981382, 9.34762...</td>\n",
       "      <td>0.623715</td>\n",
       "      <td>0.622885</td>\n",
       "      <td>0.320639</td>\n",
       "      <td>0.319732</td>\n",
       "      <td>4060.118535</td>\n",
       "      <td>1009.324771</td>\n",
       "      <td>0.022267</td>\n",
       "      <td>0.022144</td>\n",
       "      <td>0.052647</td>\n",
       "      <td>0.051991</td>\n",
       "      <td>0.300078</td>\n",
       "      <td>0.297762</td>\n",
       "      <td>0.754415</td>\n",
       "      <td>0.750567</td>\n",
       "      <td>Crazy improvement on accuracy, but loss is ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>#8 but inrodcued a fully connected layer inste...</td>\n",
       "      <td>Cyclone_bs24_de_fc.ipynb</td>\n",
       "      <td>(24, 25.0, 50.0)</td>\n",
       "      <td>[15.40937172719522, 59.354090726467895, 0.0108...</td>\n",
       "      <td>0.652142</td>\n",
       "      <td>0.65596</td>\n",
       "      <td>0.292014</td>\n",
       "      <td>0.297894</td>\n",
       "      <td>3513.459285</td>\n",
       "      <td>927.660295</td>\n",
       "      <td>0.019269</td>\n",
       "      <td>0.020352</td>\n",
       "      <td>0.155654</td>\n",
       "      <td>0.1519</td>\n",
       "      <td>0.459938</td>\n",
       "      <td>0.463821</td>\n",
       "      <td>0.645239</td>\n",
       "      <td>0.648375</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>#12 but added additional layer with N neurons.</td>\n",
       "      <td>Cyclone_bs24_de_fc_50.ipynb</td>\n",
       "      <td>(24, 25.0, 50.0)</td>\n",
       "      <td>[26.109520871935104, 49.5311967051249, -0.3452...</td>\n",
       "      <td>0.466515</td>\n",
       "      <td>0.461135</td>\n",
       "      <td>0.135376</td>\n",
       "      <td>0.133167</td>\n",
       "      <td>136.434836</td>\n",
       "      <td>45.894682</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.659451</td>\n",
       "      <td>0.662322</td>\n",
       "      <td>0.592482</td>\n",
       "      <td>0.584591</td>\n",
       "      <td>0.477945</td>\n",
       "      <td>0.470534</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Decreased amount of weights. w*b = d, a*b = e....</td>\n",
       "      <td>Cyclone_bs24_de_individual_d.ipynb</td>\n",
       "      <td>(24, 25, 50.0, 2.0)</td>\n",
       "      <td>[22.643231420511356, 53.64948422622184, 5.7163...</td>\n",
       "      <td>0.679632</td>\n",
       "      <td>0.674216</td>\n",
       "      <td>0.243784</td>\n",
       "      <td>0.241061</td>\n",
       "      <td>3817.138285</td>\n",
       "      <td>892.019559</td>\n",
       "      <td>0.020935</td>\n",
       "      <td>0.01957</td>\n",
       "      <td>0.434571</td>\n",
       "      <td>0.432412</td>\n",
       "      <td>0.793835</td>\n",
       "      <td>0.780843</td>\n",
       "      <td>0.69291</td>\n",
       "      <td>0.690757</td>\n",
       "      <td>Surprised it performed worse than #8 (multiple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>#8 but with maxpooling kernel  = 4</td>\n",
       "      <td>Cyclone_bs24_de_mpk4.ipynb</td>\n",
       "      <td>(24, 25.0, 50.0, 2.0)</td>\n",
       "      <td>[21.436433782203608, 53.543517093495865, 5.718...</td>\n",
       "      <td>0.667127</td>\n",
       "      <td>0.6617</td>\n",
       "      <td>0.25235</td>\n",
       "      <td>0.248914</td>\n",
       "      <td>3249.378729</td>\n",
       "      <td>760.498271</td>\n",
       "      <td>0.017821</td>\n",
       "      <td>0.016685</td>\n",
       "      <td>0.33432</td>\n",
       "      <td>0.33303</td>\n",
       "      <td>0.668574</td>\n",
       "      <td>0.656429</td>\n",
       "      <td>0.697278</td>\n",
       "      <td>0.694537</td>\n",
       "      <td>Loss around 50.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>#8 but with maxpooling kernel  = 6</td>\n",
       "      <td>Cyclone_bs24_de_mpk6.ipynb</td>\n",
       "      <td>(24, 25.0, 50.0, 2.0)</td>\n",
       "      <td>[21.82619591052033, 53.15656338367588, 5.70132...</td>\n",
       "      <td>0.651207</td>\n",
       "      <td>0.64591</td>\n",
       "      <td>0.249171</td>\n",
       "      <td>0.245461</td>\n",
       "      <td>2736.408532</td>\n",
       "      <td>638.681951</td>\n",
       "      <td>0.015008</td>\n",
       "      <td>0.014012</td>\n",
       "      <td>0.293579</td>\n",
       "      <td>0.292252</td>\n",
       "      <td>0.595994</td>\n",
       "      <td>0.584071</td>\n",
       "      <td>0.691604</td>\n",
       "      <td>0.690193</td>\n",
       "      <td>Loss around 30.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>Decreased amount of weights. w*b = d, a*b = e....</td>\n",
       "      <td>Cyclone_bs24_de_small_weights.ipynb</td>\n",
       "      <td>(24, 0.5, 1.0, 1.0)</td>\n",
       "      <td>[0.0896498480524493, 1.3126924946028382, 0.046...</td>\n",
       "      <td>0.619279</td>\n",
       "      <td>0.615872</td>\n",
       "      <td>0.369937</td>\n",
       "      <td>0.36192</td>\n",
       "      <td>7008.685517</td>\n",
       "      <td>1697.523861</td>\n",
       "      <td>0.038438</td>\n",
       "      <td>0.037243</td>\n",
       "      <td>0.00793</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>0.246488</td>\n",
       "      <td>0.239459</td>\n",
       "      <td>0.692676</td>\n",
       "      <td>0.690542</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Kept batch_size=24. Fixed a, b, c and taught o...</td>\n",
       "      <td>Cyclone_bs24_fixed_a_b_c.ipynb</td>\n",
       "      <td>(24, 0.5, 1.0, 50.0, 2.0)</td>\n",
       "      <td>[0.12003418944073936]</td>\n",
       "      <td>0.592018</td>\n",
       "      <td>0.595559</td>\n",
       "      <td>0.302967</td>\n",
       "      <td>0.312784</td>\n",
       "      <td>5366.609678</td>\n",
       "      <td>1416.065915</td>\n",
       "      <td>0.029433</td>\n",
       "      <td>0.031068</td>\n",
       "      <td>0.00587</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>0.189906</td>\n",
       "      <td>0.196773</td>\n",
       "      <td>0.715827</td>\n",
       "      <td>0.711555</td>\n",
       "      <td>Unsuprusingly, accuracy dropped. Suprisingly, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Kept batch_size=24. Fixed b, c, and taught a a...</td>\n",
       "      <td>Cyclone_bs24_fixed_b_c.ipynb</td>\n",
       "      <td>(24, 0.5, 1.0, 50.0, 2.0)</td>\n",
       "      <td>[0.15539169147102097, 1.2719801322792625]</td>\n",
       "      <td>0.592018</td>\n",
       "      <td>0.595559</td>\n",
       "      <td>0.302967</td>\n",
       "      <td>0.312784</td>\n",
       "      <td>5366.609678</td>\n",
       "      <td>1416.065915</td>\n",
       "      <td>0.029433</td>\n",
       "      <td>0.031068</td>\n",
       "      <td>0.00587</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>0.189906</td>\n",
       "      <td>0.196773</td>\n",
       "      <td>0.712951</td>\n",
       "      <td>0.708742</td>\n",
       "      <td>Slight improvement on train, but degradation o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>Kept batch_size = 24. Fixed c, and taught, a, ...</td>\n",
       "      <td>Cyclone_bs24_fixed_c.ipynb</td>\n",
       "      <td>(24, 0.5, 1.0, 50.0, 2.0)</td>\n",
       "      <td>[0.15830266569985793, 1.2682778724106643, 50.0...</td>\n",
       "      <td>0.591976</td>\n",
       "      <td>0.595795</td>\n",
       "      <td>0.302748</td>\n",
       "      <td>0.313353</td>\n",
       "      <td>5348.360716</td>\n",
       "      <td>1418.13895</td>\n",
       "      <td>0.029332</td>\n",
       "      <td>0.031113</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>0.005702</td>\n",
       "      <td>0.189906</td>\n",
       "      <td>0.197293</td>\n",
       "      <td>0.711351</td>\n",
       "      <td>0.708192</td>\n",
       "      <td>No change. Seems like b parameter can be remov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>Added individual weights for pixel, instead of...</td>\n",
       "      <td>Cyclone_bs24_individual_w.ipynb</td>\n",
       "      <td>(24, 0.5, 1.0, 50.0, 2.0)</td>\n",
       "      <td>[0.17598899272738172, 1.614064542046558, 50.21...</td>\n",
       "      <td>0.623672</td>\n",
       "      <td>0.621825</td>\n",
       "      <td>0.357495</td>\n",
       "      <td>0.354873</td>\n",
       "      <td>5668.026505</td>\n",
       "      <td>1407.067843</td>\n",
       "      <td>0.031086</td>\n",
       "      <td>0.03087</td>\n",
       "      <td>0.021778</td>\n",
       "      <td>0.020796</td>\n",
       "      <td>0.269121</td>\n",
       "      <td>0.264446</td>\n",
       "      <td>0.74958</td>\n",
       "      <td>0.739455</td>\n",
       "      <td>Expected BA to increase and it did.     Multip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>Removed MaxPooling from #1.</td>\n",
       "      <td>Cyclone_bs24_no_maxpool.ipynb</td>\n",
       "      <td>(24, 0.5, 1.0, 50.0, 2.0)</td>\n",
       "      <td>[0.11917891420175732, 1.2946903347826295, 50.2...</td>\n",
       "      <td>0.619219</td>\n",
       "      <td>0.6158</td>\n",
       "      <td>0.369576</td>\n",
       "      <td>0.361493</td>\n",
       "      <td>6983.122564</td>\n",
       "      <td>1689.874465</td>\n",
       "      <td>0.038298</td>\n",
       "      <td>0.037075</td>\n",
       "      <td>0.00805</td>\n",
       "      <td>0.007859</td>\n",
       "      <td>0.246488</td>\n",
       "      <td>0.239459</td>\n",
       "      <td>0.729525</td>\n",
       "      <td>0.725536</td>\n",
       "      <td>Slight decrease from #1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>#1 but all weights are from 0 to 1</td>\n",
       "      <td>Cyclone_bs24_small_weights.ipynb</td>\n",
       "      <td>(24, 0.009999999776482582, 0.01999999955296516...</td>\n",
       "      <td>[-0.16131398782119288, 0.2962770612739181, 1.2...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>#1 but all weights are from 0 to 1</td>\n",
       "      <td>Cyclone_small_weights.ipynb</td>\n",
       "      <td>(12, 0.5, 1.0, 50.0, 2.0)</td>\n",
       "      <td>[0.09569555992478619, 1.3245419775175182, 50.2...</td>\n",
       "      <td>0.619279</td>\n",
       "      <td>0.615872</td>\n",
       "      <td>0.369937</td>\n",
       "      <td>0.36192</td>\n",
       "      <td>7008.685517</td>\n",
       "      <td>1697.523861</td>\n",
       "      <td>0.038438</td>\n",
       "      <td>0.037243</td>\n",
       "      <td>0.00793</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>0.246488</td>\n",
       "      <td>0.239459</td>\n",
       "      <td>0.615946</td>\n",
       "      <td>0.619298</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                        Description  \\\n",
       "0   1  First network (10 epochs) with following layer...   \n",
       "0   2              Same network, doubled the batch_size.   \n",
       "0   3  Decreased amount of weights. w*b = d, a*b = e....   \n",
       "0   4  #8 but inrodcued a fully connected layer inste...   \n",
       "0   5     #12 but added additional layer with N neurons.   \n",
       "0   6  Decreased amount of weights. w*b = d, a*b = e....   \n",
       "0   7                 #8 but with maxpooling kernel  = 4   \n",
       "0   8                 #8 but with maxpooling kernel  = 6   \n",
       "0   9  Decreased amount of weights. w*b = d, a*b = e....   \n",
       "0  10  Kept batch_size=24. Fixed a, b, c and taught o...   \n",
       "0  11  Kept batch_size=24. Fixed b, c, and taught a a...   \n",
       "0  12  Kept batch_size = 24. Fixed c, and taught, a, ...   \n",
       "0  13  Added individual weights for pixel, instead of...   \n",
       "0  14                        Removed MaxPooling from #1.   \n",
       "0  15                 #1 but all weights are from 0 to 1   \n",
       "0  16                 #1 but all weights are from 0 to 1   \n",
       "\n",
       "                              Filename  \\\n",
       "0                        Cyclone.ipynb   \n",
       "0                   Cyclone_bs24.ipynb   \n",
       "0                Cyclone_bs24_de.ipynb   \n",
       "0             Cyclone_bs24_de_fc.ipynb   \n",
       "0          Cyclone_bs24_de_fc_50.ipynb   \n",
       "0   Cyclone_bs24_de_individual_d.ipynb   \n",
       "0           Cyclone_bs24_de_mpk4.ipynb   \n",
       "0           Cyclone_bs24_de_mpk6.ipynb   \n",
       "0  Cyclone_bs24_de_small_weights.ipynb   \n",
       "0       Cyclone_bs24_fixed_a_b_c.ipynb   \n",
       "0         Cyclone_bs24_fixed_b_c.ipynb   \n",
       "0           Cyclone_bs24_fixed_c.ipynb   \n",
       "0      Cyclone_bs24_individual_w.ipynb   \n",
       "0        Cyclone_bs24_no_maxpool.ipynb   \n",
       "0     Cyclone_bs24_small_weights.ipynb   \n",
       "0          Cyclone_small_weights.ipynb   \n",
       "\n",
       "                                     Hyperparameters  \\\n",
       "0                          (12, 0.5, 1.0, 50.0, 2.0)   \n",
       "0                          (24, 0.5, 1.0, 50.0, 2.0)   \n",
       "0                              (24, 25.0, 50.0, 2.0)   \n",
       "0                                   (24, 25.0, 50.0)   \n",
       "0                                   (24, 25.0, 50.0)   \n",
       "0                                (24, 25, 50.0, 2.0)   \n",
       "0                              (24, 25.0, 50.0, 2.0)   \n",
       "0                              (24, 25.0, 50.0, 2.0)   \n",
       "0                                (24, 0.5, 1.0, 1.0)   \n",
       "0                          (24, 0.5, 1.0, 50.0, 2.0)   \n",
       "0                          (24, 0.5, 1.0, 50.0, 2.0)   \n",
       "0                          (24, 0.5, 1.0, 50.0, 2.0)   \n",
       "0                          (24, 0.5, 1.0, 50.0, 2.0)   \n",
       "0                          (24, 0.5, 1.0, 50.0, 2.0)   \n",
       "0  (24, 0.009999999776482582, 0.01999999955296516...   \n",
       "0                          (12, 0.5, 1.0, 50.0, 2.0)   \n",
       "\n",
       "                           Resulting_hyperparameters  BA_train   BA_test  \\\n",
       "0  [0.08904803785546497, 1.3161153018450304, 50.2...  0.619279  0.615872   \n",
       "0  [0.12595123010387912, 1.3041119290093375, 50.2...  0.619279  0.615872   \n",
       "0  [12.55361778953873, 62.36485336981382, 9.34762...  0.623715  0.622885   \n",
       "0  [15.40937172719522, 59.354090726467895, 0.0108...  0.652142   0.65596   \n",
       "0  [26.109520871935104, 49.5311967051249, -0.3452...  0.466515  0.461135   \n",
       "0  [22.643231420511356, 53.64948422622184, 5.7163...  0.679632  0.674216   \n",
       "0  [21.436433782203608, 53.543517093495865, 5.718...  0.667127    0.6617   \n",
       "0  [21.82619591052033, 53.15656338367588, 5.70132...  0.651207   0.64591   \n",
       "0  [0.0896498480524493, 1.3126924946028382, 0.046...  0.619279  0.615872   \n",
       "0                              [0.12003418944073936]  0.592018  0.595559   \n",
       "0          [0.15539169147102097, 1.2719801322792625]  0.592018  0.595559   \n",
       "0  [0.15830266569985793, 1.2682778724106643, 50.0...  0.591976  0.595795   \n",
       "0  [0.17598899272738172, 1.614064542046558, 50.21...  0.623672  0.621825   \n",
       "0  [0.11917891420175732, 1.2946903347826295, 50.2...  0.619219    0.6158   \n",
       "0  [-0.16131398782119288, 0.2962770612739181, 1.2...       0.5       0.5   \n",
       "0  [0.09569555992478619, 1.3245419775175182, 50.2...  0.619279  0.615872   \n",
       "\n",
       "   F1_train   F1_test      G_train       G_test   I_train    I_test fpr_train  \\\n",
       "0  0.369937   0.36192  7008.685517  1697.523861  0.038438  0.037243   0.00793   \n",
       "0  0.369937   0.36192  7008.685517  1697.523861  0.038438  0.037243   0.00793   \n",
       "0  0.320639  0.319732  4060.118535  1009.324771  0.022267  0.022144  0.052647   \n",
       "0  0.292014  0.297894  3513.459285   927.660295  0.019269  0.020352  0.155654   \n",
       "0  0.135376  0.133167   136.434836    45.894682  0.000748  0.001007  0.659451   \n",
       "0  0.243784  0.241061  3817.138285   892.019559  0.020935   0.01957  0.434571   \n",
       "0   0.25235  0.248914  3249.378729   760.498271  0.017821  0.016685   0.33432   \n",
       "0  0.249171  0.245461  2736.408532   638.681951  0.015008  0.014012  0.293579   \n",
       "0  0.369937   0.36192  7008.685517  1697.523861  0.038438  0.037243   0.00793   \n",
       "0  0.302967  0.312784  5366.609678  1416.065915  0.029433  0.031068   0.00587   \n",
       "0  0.302967  0.312784  5366.609678  1416.065915  0.029433  0.031068   0.00587   \n",
       "0  0.302748  0.313353  5348.360716   1418.13895  0.029332  0.031113  0.005954   \n",
       "0  0.357495  0.354873  5668.026505  1407.067843  0.031086   0.03087  0.021778   \n",
       "0  0.369576  0.361493  6983.122564  1689.874465  0.038298  0.037075   0.00805   \n",
       "0       0.0       0.0            0            0         0         0       0.0   \n",
       "0  0.369937   0.36192  7008.685517  1697.523861  0.038438  0.037243   0.00793   \n",
       "\n",
       "   fpr_test tpr_train  tpr_test auc_train  auc_test  \\\n",
       "0  0.007715  0.246488  0.239459  0.619309  0.615954   \n",
       "0  0.007715  0.246488  0.239459  0.696043  0.700299   \n",
       "0  0.051991  0.300078  0.297762  0.754415  0.750567   \n",
       "0    0.1519  0.459938  0.463821  0.645239  0.648375   \n",
       "0  0.662322  0.592482  0.584591  0.477945  0.470534   \n",
       "0  0.432412  0.793835  0.780843   0.69291  0.690757   \n",
       "0   0.33303  0.668574  0.656429  0.697278  0.694537   \n",
       "0  0.292252  0.595994  0.584071  0.691604  0.690193   \n",
       "0  0.007715  0.246488  0.239459  0.692676  0.690542   \n",
       "0  0.005654  0.189906  0.196773  0.715827  0.711555   \n",
       "0  0.005654  0.189906  0.196773  0.712951  0.708742   \n",
       "0  0.005702  0.189906  0.197293  0.711351  0.708192   \n",
       "0  0.020796  0.269121  0.264446   0.74958  0.739455   \n",
       "0  0.007859  0.246488  0.239459  0.729525  0.725536   \n",
       "0       0.0       0.0       0.0       0.5       0.5   \n",
       "0  0.007715  0.246488  0.239459  0.615946  0.619298   \n",
       "\n",
       "                                             Comment  \n",
       "0                                       Pretty nice.  \n",
       "0                 Surprised statistics are unchanged  \n",
       "0  Crazy improvement on accuracy, but loss is ver...  \n",
       "0                                                NaN  \n",
       "0                                                NaN  \n",
       "0  Surprised it performed worse than #8 (multiple...  \n",
       "0                                    Loss around 50.  \n",
       "0                                    Loss around 30.  \n",
       "0                                                NaN  \n",
       "0  Unsuprusingly, accuracy dropped. Suprisingly, ...  \n",
       "0  Slight improvement on train, but degradation o...  \n",
       "0  No change. Seems like b parameter can be remov...  \n",
       "0  Expected BA to increase and it did.     Multip...  \n",
       "0                           Slight decrease from #1.  \n",
       "0                                                NaN  \n",
       "0                                                NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_final_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mlunn2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7906f88924d0acbcc878920ce9dbcc77a020e1b0135b8245f9ac081820afa623"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
