{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T05:39:50.592720Z",
     "iopub.status.busy": "2022-11-24T05:39:50.592720Z",
     "iopub.status.idle": "2022-11-24T05:39:51.591628Z",
     "shell.execute_reply": "2022-11-24T05:39:51.590627Z"
    }
   },
   "outputs": [],
   "source": [
    "from make_final_table import make_final_table\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T05:39:51.596632Z",
     "iopub.status.busy": "2022-11-24T05:39:51.595631Z",
     "iopub.status.idle": "2022-11-24T05:39:52.678602Z",
     "shell.execute_reply": "2022-11-24T05:39:52.678602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Description</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Hyperparameters</th>\n",
       "      <th>Resulting_hyperparameters</th>\n",
       "      <th>Conf_mx_train_row1</th>\n",
       "      <th>Conf_mx_train_row2</th>\n",
       "      <th>Conf_mx_test_row1</th>\n",
       "      <th>Conf_mx_test_row2</th>\n",
       "      <th>BA_train</th>\n",
       "      <th>...</th>\n",
       "      <th>G_test</th>\n",
       "      <th>I_train</th>\n",
       "      <th>I_test</th>\n",
       "      <th>fpr_train</th>\n",
       "      <th>fpr_test</th>\n",
       "      <th>tpr_train</th>\n",
       "      <th>tpr_test</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_test</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>First network (10 epochs) with following layer...</td>\n",
       "      <td>Cyclone.ipynb</td>\n",
       "      <td>(12, 0.5, 1.0, 50.0, 2.0)</td>\n",
       "      <td>[0.1012469578228546, 1.3518889736129378, 50.21...</td>\n",
       "      <td>[37. 67.]</td>\n",
       "      <td>[  216. 10210.]</td>\n",
       "      <td>[15. 15.]</td>\n",
       "      <td>[  59. 2460.]</td>\n",
       "      <td>0.569863</td>\n",
       "      <td>...</td>\n",
       "      <td>68.483088</td>\n",
       "      <td>0.007069</td>\n",
       "      <td>0.013433</td>\n",
       "      <td>0.006519</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.146245</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.646953</td>\n",
       "      <td>0.673994</td>\n",
       "      <td>Pretty nice.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Same network, doubled the batch_size.</td>\n",
       "      <td>Cyclone_bs24.ipynb</td>\n",
       "      <td>(24, 0.5, 1.0, 50.0, 2.0)</td>\n",
       "      <td>[0.14767121958700888, 1.315396569039503, 50.01...</td>\n",
       "      <td>[23. 51.]</td>\n",
       "      <td>[  230. 10226.]</td>\n",
       "      <td>[ 9. 11.]</td>\n",
       "      <td>[  65. 2463.]</td>\n",
       "      <td>0.542973</td>\n",
       "      <td>...</td>\n",
       "      <td>37.858288</td>\n",
       "      <td>0.003996</td>\n",
       "      <td>0.007429</td>\n",
       "      <td>0.004963</td>\n",
       "      <td>0.004446</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.121622</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Surprised statistics are unchanged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Decreased amount of weights. w*b = d, a*b = e....</td>\n",
       "      <td>Cyclone_bs24_de.ipynb</td>\n",
       "      <td>(24, 25.0, 50.0, 2.0)</td>\n",
       "      <td>[16.22554311126304, 58.74109040769373, 1.69754...</td>\n",
       "      <td>[ 217. 2590.]</td>\n",
       "      <td>[  36. 7687.]</td>\n",
       "      <td>[ 64. 519.]</td>\n",
       "      <td>[  10. 1956.]</td>\n",
       "      <td>0.802844</td>\n",
       "      <td>...</td>\n",
       "      <td>140.595058</td>\n",
       "      <td>0.019011</td>\n",
       "      <td>0.027578</td>\n",
       "      <td>0.252019</td>\n",
       "      <td>0.209697</td>\n",
       "      <td>0.857708</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.822687</td>\n",
       "      <td>0.849568</td>\n",
       "      <td>Crazy improvement on accuracy, but loss is ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>#8 but inrodcued a fully connected layer inste...</td>\n",
       "      <td>Cyclone_bs24_de_fc.ipynb</td>\n",
       "      <td>(24, 25.0, 50.0)</td>\n",
       "      <td>[21.473467915485646, 53.359385095975036, -0.01...</td>\n",
       "      <td>[ 117. 1980.]</td>\n",
       "      <td>[ 136. 8296.]</td>\n",
       "      <td>[ 42. 441.]</td>\n",
       "      <td>[  32. 2034.]</td>\n",
       "      <td>0.634884</td>\n",
       "      <td>...</td>\n",
       "      <td>54.035928</td>\n",
       "      <td>0.004342</td>\n",
       "      <td>0.010599</td>\n",
       "      <td>0.192682</td>\n",
       "      <td>0.178182</td>\n",
       "      <td>0.462451</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.639169</td>\n",
       "      <td>0.700295</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>#12 but added additional layer with N neurons.</td>\n",
       "      <td>Cyclone_bs24_de_fc_50.ipynb</td>\n",
       "      <td>(24, 25.0, 50.0)</td>\n",
       "      <td>[24.68038704188609, 50.52135963153863, -0.2352...</td>\n",
       "      <td>[14. 90.]</td>\n",
       "      <td>[  239. 10187.]</td>\n",
       "      <td>[ 6. 27.]</td>\n",
       "      <td>[  68. 2447.]</td>\n",
       "      <td>0.523289</td>\n",
       "      <td>...</td>\n",
       "      <td>13.132992</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>0.010914</td>\n",
       "      <td>0.055336</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.519186</td>\n",
       "      <td>0.528111</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Kept batch_size=24. Fixed b, c, and taught a a...</td>\n",
       "      <td>Cyclone_bs24_de_fixed_c.ipynb</td>\n",
       "      <td>(24, 25.0, 50.0, 2.0)</td>\n",
       "      <td>[12.28896979130295, 62.65385386670118]</td>\n",
       "      <td>[158. 871.]</td>\n",
       "      <td>[  95. 9406.]</td>\n",
       "      <td>[ 50. 166.]</td>\n",
       "      <td>[  24. 2309.]</td>\n",
       "      <td>0.769877</td>\n",
       "      <td>...</td>\n",
       "      <td>168.481133</td>\n",
       "      <td>0.020892</td>\n",
       "      <td>0.033048</td>\n",
       "      <td>0.084752</td>\n",
       "      <td>0.067071</td>\n",
       "      <td>0.624506</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.868346</td>\n",
       "      <td>0.895457</td>\n",
       "      <td>Slight improvement on train, but degradation o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Kept batch_size=24. Fixed c, and taught d and ...</td>\n",
       "      <td>Cyclone_bs24_de_fixed_c_individual_d.ipynb</td>\n",
       "      <td>(24, 25, 50.0, 2.0)</td>\n",
       "      <td>[24.87046767764879, 80.37724033952323]</td>\n",
       "      <td>[ 225. 3213.]</td>\n",
       "      <td>[  28. 7063.]</td>\n",
       "      <td>[ 66. 649.]</td>\n",
       "      <td>[   8. 1825.]</td>\n",
       "      <td>0.788329</td>\n",
       "      <td>...</td>\n",
       "      <td>126.47033</td>\n",
       "      <td>0.017038</td>\n",
       "      <td>0.024818</td>\n",
       "      <td>0.31267</td>\n",
       "      <td>0.262328</td>\n",
       "      <td>0.889328</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.802464</td>\n",
       "      <td>0.830347</td>\n",
       "      <td>Slight improvement on train, but degradation o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Kept batch_size=24. Fixed c, maxpool kernel = 3</td>\n",
       "      <td>Cyclone_bs24_de_fixed_c_mpk3.ipynb</td>\n",
       "      <td>(24, 25.0, 50.0, 2.0)</td>\n",
       "      <td>[15.92891528087388, 59.03124590095707]</td>\n",
       "      <td>[ 209. 2295.]</td>\n",
       "      <td>[  44. 7982.]</td>\n",
       "      <td>[ 62. 452.]</td>\n",
       "      <td>[  12. 2023.]</td>\n",
       "      <td>0.801386</td>\n",
       "      <td>...</td>\n",
       "      <td>144.058996</td>\n",
       "      <td>0.019115</td>\n",
       "      <td>0.028258</td>\n",
       "      <td>0.223314</td>\n",
       "      <td>0.182626</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.832632</td>\n",
       "      <td>0.861589</td>\n",
       "      <td>Slight improvement on train, but degradation o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>Decreased amount of weights. w*b = d, a*b = e....</td>\n",
       "      <td>Cyclone_bs24_de_individual_d.ipynb</td>\n",
       "      <td>(24, 25, 50.0, 2.0)</td>\n",
       "      <td>[23.34613924628127, 52.71054096143292, 2.54126...</td>\n",
       "      <td>[ 242. 5354.]</td>\n",
       "      <td>[  11. 4923.]</td>\n",
       "      <td>[  70. 1144.]</td>\n",
       "      <td>[   4. 1330.]</td>\n",
       "      <td>0.717776</td>\n",
       "      <td>...</td>\n",
       "      <td>79.807291</td>\n",
       "      <td>0.011238</td>\n",
       "      <td>0.015661</td>\n",
       "      <td>0.520969</td>\n",
       "      <td>0.462409</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.718817</td>\n",
       "      <td>0.747149</td>\n",
       "      <td>Surprised it performed worse than #8 (multiple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>#8 but with maxpooling kernel  = 3</td>\n",
       "      <td>Cyclone_bs24_de_mpk3.ipynb</td>\n",
       "      <td>(24, 25.0, 50.0, 2.0)</td>\n",
       "      <td>[15.962038215573319, 58.99740815983707, 1.6286...</td>\n",
       "      <td>[ 214. 2422.]</td>\n",
       "      <td>[  39. 7855.]</td>\n",
       "      <td>[ 65. 480.]</td>\n",
       "      <td>[   9. 1994.]</td>\n",
       "      <td>0.805089</td>\n",
       "      <td>...</td>\n",
       "      <td>155.997398</td>\n",
       "      <td>0.019452</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.235672</td>\n",
       "      <td>0.194018</td>\n",
       "      <td>0.84585</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>0.827754</td>\n",
       "      <td>0.854297</td>\n",
       "      <td>Loss around 50.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>#8 but with maxpooling kernel  = 4</td>\n",
       "      <td>Cyclone_bs24_de_mpk4.ipynb</td>\n",
       "      <td>(24, 25.0, 50.0, 2.0)</td>\n",
       "      <td>[15.926760859977419, 59.02518089808666, 1.5974...</td>\n",
       "      <td>[ 207. 2322.]</td>\n",
       "      <td>[  46. 7955.]</td>\n",
       "      <td>[ 62. 460.]</td>\n",
       "      <td>[  12. 2014.]</td>\n",
       "      <td>0.79612</td>\n",
       "      <td>...</td>\n",
       "      <td>142.066991</td>\n",
       "      <td>0.018397</td>\n",
       "      <td>0.027878</td>\n",
       "      <td>0.225941</td>\n",
       "      <td>0.185934</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.824285</td>\n",
       "      <td>0.851263</td>\n",
       "      <td>Loss around 50.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>#8 but with maxpooling kernel  = 6</td>\n",
       "      <td>Cyclone_bs24_de_mpk6.ipynb</td>\n",
       "      <td>(24, 25.0, 50.0, 2.0)</td>\n",
       "      <td>[22.26584152645176, 52.717357406099694, 2.4293...</td>\n",
       "      <td>[ 233. 4325.]</td>\n",
       "      <td>[  20. 5952.]</td>\n",
       "      <td>[ 68. 897.]</td>\n",
       "      <td>[   6. 1577.]</td>\n",
       "      <td>0.750053</td>\n",
       "      <td>...</td>\n",
       "      <td>98.872579</td>\n",
       "      <td>0.013251</td>\n",
       "      <td>0.019402</td>\n",
       "      <td>0.420843</td>\n",
       "      <td>0.362571</td>\n",
       "      <td>0.920949</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.753481</td>\n",
       "      <td>0.783556</td>\n",
       "      <td>Loss around 30.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>Decreased amount of weights. w*b = d, a*b = e....</td>\n",
       "      <td>Cyclone_bs24_de_small_weights.ipynb</td>\n",
       "      <td>(24, 0.5, 1.0, 1.0)</td>\n",
       "      <td>[0.08218413911453387, 1.2872405067497392, -0.0...</td>\n",
       "      <td>[  253. 10277.]</td>\n",
       "      <td>[0. 0.]</td>\n",
       "      <td>[  74. 2475.]</td>\n",
       "      <td>[0. 0.]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569863</td>\n",
       "      <td>0.598321</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>Kept batch_size=24. Fixed a, b, c and taught o...</td>\n",
       "      <td>Cyclone_bs24_fixed_a_b_c.ipynb</td>\n",
       "      <td>(24, 0.5, 1.0, 50.0, 2.0)</td>\n",
       "      <td>[0.12522902479033046]</td>\n",
       "      <td>[24. 54.]</td>\n",
       "      <td>[  229. 10222.]</td>\n",
       "      <td>[ 9. 12.]</td>\n",
       "      <td>[  65. 2463.]</td>\n",
       "      <td>0.544803</td>\n",
       "      <td>...</td>\n",
       "      <td>36.760634</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>0.094862</td>\n",
       "      <td>0.121622</td>\n",
       "      <td>0.848893</td>\n",
       "      <td>0.871787</td>\n",
       "      <td>Unsuprusingly, accuracy dropped. Suprisingly, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>Kept batch_size=24. Fixed b, c, and taught a a...</td>\n",
       "      <td>Cyclone_bs24_fixed_b_c.ipynb</td>\n",
       "      <td>(24, 0.5, 1.0, 50.0, 2.0)</td>\n",
       "      <td>[0.1715280727831673, 1.2905634412968365]</td>\n",
       "      <td>[ 50. 114.]</td>\n",
       "      <td>[  203. 10163.]</td>\n",
       "      <td>[15. 22.]</td>\n",
       "      <td>[  59. 2452.]</td>\n",
       "      <td>0.593268</td>\n",
       "      <td>...</td>\n",
       "      <td>60.432255</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.011859</td>\n",
       "      <td>0.011093</td>\n",
       "      <td>0.008892</td>\n",
       "      <td>0.197628</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.843245</td>\n",
       "      <td>0.873159</td>\n",
       "      <td>Slight improvement on train, but degradation o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>Kept batch_size = 24. Fixed c, and taught, a, ...</td>\n",
       "      <td>Cyclone_bs24_fixed_c.ipynb</td>\n",
       "      <td>(24, 0.5, 1.0, 50.0, 2.0)</td>\n",
       "      <td>[0.17152356876739472, 1.290571821136347, 49.95...</td>\n",
       "      <td>[ 50. 114.]</td>\n",
       "      <td>[  203. 10163.]</td>\n",
       "      <td>[15. 22.]</td>\n",
       "      <td>[  59. 2452.]</td>\n",
       "      <td>0.593268</td>\n",
       "      <td>...</td>\n",
       "      <td>60.432255</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.011859</td>\n",
       "      <td>0.011093</td>\n",
       "      <td>0.008892</td>\n",
       "      <td>0.197628</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.843245</td>\n",
       "      <td>0.873159</td>\n",
       "      <td>No change. Seems like b parameter can be remov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>Added individual weights for pixel, instead of...</td>\n",
       "      <td>Cyclone_bs24_individual_w.ipynb</td>\n",
       "      <td>(24, 0.5, 1.0, 50.0, 2.0)</td>\n",
       "      <td>[0.1905909344562639, 1.40656480486549, 50.1403...</td>\n",
       "      <td>[141. 944.]</td>\n",
       "      <td>[ 112. 9333.]</td>\n",
       "      <td>[ 38. 174.]</td>\n",
       "      <td>[  36. 2300.]</td>\n",
       "      <td>0.732728</td>\n",
       "      <td>...</td>\n",
       "      <td>98.341769</td>\n",
       "      <td>0.015775</td>\n",
       "      <td>0.019298</td>\n",
       "      <td>0.091856</td>\n",
       "      <td>0.070331</td>\n",
       "      <td>0.557312</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.850618</td>\n",
       "      <td>0.877575</td>\n",
       "      <td>Expected BA to increase and it did.     Multip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>Removed MaxPooling from #1.</td>\n",
       "      <td>Cyclone_bs24_no_maxpool.ipynb</td>\n",
       "      <td>(24, 0.5, 1.0, 50.0, 2.0)</td>\n",
       "      <td>[0.13866698537909572, 1.3260021845179213, 50.1...</td>\n",
       "      <td>[27. 55.]</td>\n",
       "      <td>[  226. 10222.]</td>\n",
       "      <td>[12. 12.]</td>\n",
       "      <td>[  62. 2463.]</td>\n",
       "      <td>0.550684</td>\n",
       "      <td>...</td>\n",
       "      <td>54.273569</td>\n",
       "      <td>0.004879</td>\n",
       "      <td>0.010646</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>0.106719</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.850141</td>\n",
       "      <td>0.887074</td>\n",
       "      <td>Slight decrease from #1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>#1 but all weights are from 0 to 1</td>\n",
       "      <td>Cyclone_bs24_small_weights.ipynb</td>\n",
       "      <td>(24, 0.009999999776482582, 0.01999999955296516...</td>\n",
       "      <td>[-6.064823740688802, 0.39064968121697785, 0.51...</td>\n",
       "      <td>[0. 0.]</td>\n",
       "      <td>[  253. 10277.]</td>\n",
       "      <td>[0. 0.]</td>\n",
       "      <td>[  74. 2475.]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                        Description  \\\n",
       "0   1  First network (10 epochs) with following layer...   \n",
       "0   2              Same network, doubled the batch_size.   \n",
       "0   3  Decreased amount of weights. w*b = d, a*b = e....   \n",
       "0   4  #8 but inrodcued a fully connected layer inste...   \n",
       "0   5     #12 but added additional layer with N neurons.   \n",
       "0   6  Kept batch_size=24. Fixed b, c, and taught a a...   \n",
       "0   7  Kept batch_size=24. Fixed c, and taught d and ...   \n",
       "0   8    Kept batch_size=24. Fixed c, maxpool kernel = 3   \n",
       "0   9  Decreased amount of weights. w*b = d, a*b = e....   \n",
       "0  10                 #8 but with maxpooling kernel  = 3   \n",
       "0  11                 #8 but with maxpooling kernel  = 4   \n",
       "0  12                 #8 but with maxpooling kernel  = 6   \n",
       "0  13  Decreased amount of weights. w*b = d, a*b = e....   \n",
       "0  14  Kept batch_size=24. Fixed a, b, c and taught o...   \n",
       "0  15  Kept batch_size=24. Fixed b, c, and taught a a...   \n",
       "0  16  Kept batch_size = 24. Fixed c, and taught, a, ...   \n",
       "0  17  Added individual weights for pixel, instead of...   \n",
       "0  18                        Removed MaxPooling from #1.   \n",
       "0  19                 #1 but all weights are from 0 to 1   \n",
       "\n",
       "                                     Filename  \\\n",
       "0                               Cyclone.ipynb   \n",
       "0                          Cyclone_bs24.ipynb   \n",
       "0                       Cyclone_bs24_de.ipynb   \n",
       "0                    Cyclone_bs24_de_fc.ipynb   \n",
       "0                 Cyclone_bs24_de_fc_50.ipynb   \n",
       "0               Cyclone_bs24_de_fixed_c.ipynb   \n",
       "0  Cyclone_bs24_de_fixed_c_individual_d.ipynb   \n",
       "0          Cyclone_bs24_de_fixed_c_mpk3.ipynb   \n",
       "0          Cyclone_bs24_de_individual_d.ipynb   \n",
       "0                  Cyclone_bs24_de_mpk3.ipynb   \n",
       "0                  Cyclone_bs24_de_mpk4.ipynb   \n",
       "0                  Cyclone_bs24_de_mpk6.ipynb   \n",
       "0         Cyclone_bs24_de_small_weights.ipynb   \n",
       "0              Cyclone_bs24_fixed_a_b_c.ipynb   \n",
       "0                Cyclone_bs24_fixed_b_c.ipynb   \n",
       "0                  Cyclone_bs24_fixed_c.ipynb   \n",
       "0             Cyclone_bs24_individual_w.ipynb   \n",
       "0               Cyclone_bs24_no_maxpool.ipynb   \n",
       "0            Cyclone_bs24_small_weights.ipynb   \n",
       "\n",
       "                                     Hyperparameters  \\\n",
       "0                          (12, 0.5, 1.0, 50.0, 2.0)   \n",
       "0                          (24, 0.5, 1.0, 50.0, 2.0)   \n",
       "0                              (24, 25.0, 50.0, 2.0)   \n",
       "0                                   (24, 25.0, 50.0)   \n",
       "0                                   (24, 25.0, 50.0)   \n",
       "0                              (24, 25.0, 50.0, 2.0)   \n",
       "0                                (24, 25, 50.0, 2.0)   \n",
       "0                              (24, 25.0, 50.0, 2.0)   \n",
       "0                                (24, 25, 50.0, 2.0)   \n",
       "0                              (24, 25.0, 50.0, 2.0)   \n",
       "0                              (24, 25.0, 50.0, 2.0)   \n",
       "0                              (24, 25.0, 50.0, 2.0)   \n",
       "0                                (24, 0.5, 1.0, 1.0)   \n",
       "0                          (24, 0.5, 1.0, 50.0, 2.0)   \n",
       "0                          (24, 0.5, 1.0, 50.0, 2.0)   \n",
       "0                          (24, 0.5, 1.0, 50.0, 2.0)   \n",
       "0                          (24, 0.5, 1.0, 50.0, 2.0)   \n",
       "0                          (24, 0.5, 1.0, 50.0, 2.0)   \n",
       "0  (24, 0.009999999776482582, 0.01999999955296516...   \n",
       "\n",
       "                           Resulting_hyperparameters Conf_mx_train_row1  \\\n",
       "0  [0.1012469578228546, 1.3518889736129378, 50.21...          [37. 67.]   \n",
       "0  [0.14767121958700888, 1.315396569039503, 50.01...          [23. 51.]   \n",
       "0  [16.22554311126304, 58.74109040769373, 1.69754...      [ 217. 2590.]   \n",
       "0  [21.473467915485646, 53.359385095975036, -0.01...      [ 117. 1980.]   \n",
       "0  [24.68038704188609, 50.52135963153863, -0.2352...          [14. 90.]   \n",
       "0             [12.28896979130295, 62.65385386670118]        [158. 871.]   \n",
       "0             [24.87046767764879, 80.37724033952323]      [ 225. 3213.]   \n",
       "0             [15.92891528087388, 59.03124590095707]      [ 209. 2295.]   \n",
       "0  [23.34613924628127, 52.71054096143292, 2.54126...      [ 242. 5354.]   \n",
       "0  [15.962038215573319, 58.99740815983707, 1.6286...      [ 214. 2422.]   \n",
       "0  [15.926760859977419, 59.02518089808666, 1.5974...      [ 207. 2322.]   \n",
       "0  [22.26584152645176, 52.717357406099694, 2.4293...      [ 233. 4325.]   \n",
       "0  [0.08218413911453387, 1.2872405067497392, -0.0...    [  253. 10277.]   \n",
       "0                              [0.12522902479033046]          [24. 54.]   \n",
       "0           [0.1715280727831673, 1.2905634412968365]        [ 50. 114.]   \n",
       "0  [0.17152356876739472, 1.290571821136347, 49.95...        [ 50. 114.]   \n",
       "0  [0.1905909344562639, 1.40656480486549, 50.1403...        [141. 944.]   \n",
       "0  [0.13866698537909572, 1.3260021845179213, 50.1...          [27. 55.]   \n",
       "0  [-6.064823740688802, 0.39064968121697785, 0.51...            [0. 0.]   \n",
       "\n",
       "  Conf_mx_train_row2 Conf_mx_test_row1 Conf_mx_test_row2  BA_train  ...  \\\n",
       "0    [  216. 10210.]         [15. 15.]     [  59. 2460.]  0.569863  ...   \n",
       "0    [  230. 10226.]         [ 9. 11.]     [  65. 2463.]  0.542973  ...   \n",
       "0      [  36. 7687.]       [ 64. 519.]     [  10. 1956.]  0.802844  ...   \n",
       "0      [ 136. 8296.]       [ 42. 441.]     [  32. 2034.]  0.634884  ...   \n",
       "0    [  239. 10187.]         [ 6. 27.]     [  68. 2447.]  0.523289  ...   \n",
       "0      [  95. 9406.]       [ 50. 166.]     [  24. 2309.]  0.769877  ...   \n",
       "0      [  28. 7063.]       [ 66. 649.]     [   8. 1825.]  0.788329  ...   \n",
       "0      [  44. 7982.]       [ 62. 452.]     [  12. 2023.]  0.801386  ...   \n",
       "0      [  11. 4923.]     [  70. 1144.]     [   4. 1330.]  0.717776  ...   \n",
       "0      [  39. 7855.]       [ 65. 480.]     [   9. 1994.]  0.805089  ...   \n",
       "0      [  46. 7955.]       [ 62. 460.]     [  12. 2014.]   0.79612  ...   \n",
       "0      [  20. 5952.]       [ 68. 897.]     [   6. 1577.]  0.750053  ...   \n",
       "0            [0. 0.]     [  74. 2475.]           [0. 0.]       0.5  ...   \n",
       "0    [  229. 10222.]         [ 9. 12.]     [  65. 2463.]  0.544803  ...   \n",
       "0    [  203. 10163.]         [15. 22.]     [  59. 2452.]  0.593268  ...   \n",
       "0    [  203. 10163.]         [15. 22.]     [  59. 2452.]  0.593268  ...   \n",
       "0      [ 112. 9333.]       [ 38. 174.]     [  36. 2300.]  0.732728  ...   \n",
       "0    [  226. 10222.]         [12. 12.]     [  62. 2463.]  0.550684  ...   \n",
       "0    [  253. 10277.]           [0. 0.]     [  74. 2475.]       0.5  ...   \n",
       "\n",
       "       G_test   I_train    I_test fpr_train  fpr_test tpr_train  tpr_test  \\\n",
       "0   68.483088  0.007069  0.013433  0.006519  0.006061  0.146245  0.202703   \n",
       "0   37.858288  0.003996  0.007429  0.004963  0.004446  0.090909  0.121622   \n",
       "0  140.595058  0.019011  0.027578  0.252019  0.209697  0.857708  0.864865   \n",
       "0   54.035928  0.004342  0.010599  0.192682  0.178182  0.462451  0.567568   \n",
       "0   13.132992  0.001289  0.002577  0.008757  0.010914  0.055336  0.081081   \n",
       "0  168.481133  0.020892  0.033048  0.084752  0.067071  0.624506  0.675676   \n",
       "0   126.47033  0.017038  0.024818   0.31267  0.262328  0.889328  0.891892   \n",
       "0  144.058996  0.019115  0.028258  0.223314  0.182626  0.826087  0.837838   \n",
       "0   79.807291  0.011238  0.015661  0.520969  0.462409  0.956522  0.945946   \n",
       "0  155.997398  0.019452  0.030612  0.235672  0.194018   0.84585  0.878378   \n",
       "0  142.066991  0.018397  0.027878  0.225941  0.185934  0.818182  0.837838   \n",
       "0   98.872579  0.013251  0.019402  0.420843  0.362571  0.920949  0.918919   \n",
       "0           0         0         0       1.0       1.0       1.0       1.0   \n",
       "0   36.760634  0.004149  0.007211  0.005255  0.004848  0.094862  0.121622   \n",
       "0   60.432255  0.008832  0.011859  0.011093  0.008892  0.197628  0.202703   \n",
       "0   60.432255  0.008832  0.011859  0.011093  0.008892  0.197628  0.202703   \n",
       "0   98.341769  0.015775  0.019298  0.091856  0.070331  0.557312  0.513514   \n",
       "0   54.273569  0.004879  0.010646  0.005352  0.004848  0.106719  0.162162   \n",
       "0           0         0         0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "  auc_train  auc_test                                            Comment  \n",
       "0  0.646953  0.673994                                       Pretty nice.  \n",
       "0       0.5       0.5                 Surprised statistics are unchanged  \n",
       "0  0.822687  0.849568  Crazy improvement on accuracy, but loss is ver...  \n",
       "0  0.639169  0.700295                                                NaN  \n",
       "0  0.519186  0.528111                                                NaN  \n",
       "0  0.868346  0.895457  Slight improvement on train, but degradation o...  \n",
       "0  0.802464  0.830347  Slight improvement on train, but degradation o...  \n",
       "0  0.832632  0.861589  Slight improvement on train, but degradation o...  \n",
       "0  0.718817  0.747149  Surprised it performed worse than #8 (multiple...  \n",
       "0  0.827754  0.854297                                    Loss around 50.  \n",
       "0  0.824285  0.851263                                    Loss around 50.  \n",
       "0  0.753481  0.783556                                    Loss around 30.  \n",
       "0  0.569863  0.598321                                                NaN  \n",
       "0  0.848893  0.871787  Unsuprusingly, accuracy dropped. Suprisingly, ...  \n",
       "0  0.843245  0.873159  Slight improvement on train, but degradation o...  \n",
       "0  0.843245  0.873159  No change. Seems like b parameter can be remov...  \n",
       "0  0.850618  0.877575  Expected BA to increase and it did.     Multip...  \n",
       "0  0.850141  0.887074                           Slight decrease from #1.  \n",
       "0       0.5       0.5                                                NaN  \n",
       "\n",
       "[19 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_final_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mlunn2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7906f88924d0acbcc878920ce9dbcc77a020e1b0135b8245f9ac081820afa623"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
