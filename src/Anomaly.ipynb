{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import copy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from config_reader import Config\n",
    "from read_data import read_data\n",
    "from preproc_data import *\n",
    "from label_data import label_data\n",
    "from split_data import split_data\n",
    "from detection import *\n",
    "from pathlib import Path\n",
    "from size_out import conv2d_size_out\n",
    "\n",
    "cfg = Config()\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone_events, data = read_data(path='../data')\n",
    "# Consider renaming first variable\n",
    "cyclone_events_data, data, metrics = preproc_data(cyclone_events, metrics=data)\n",
    "labels, events = label_data(cyclone_events_data.ce2)\n",
    "no_cyclone_data = cyclone_events_data.ce2[:, :, labels == 0]\n",
    "\n",
    "train_data = no_cyclone_data\n",
    "test_data = cyclone_events_data.ce2\n",
    "\n",
    "train_data = torch.tensor(no_cyclone_data, dtype=torch.double)\n",
    "test_data = torch.tensor(cyclone_events_data.ce2, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = \"Encoder-decoder that tries to catch anomalies.\"\n",
    "filename = \"Anomaly.ipynb\"\n",
    "network_name = filename.split('.')[0]\n",
    "comment = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.conv2d_1_enc = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=2)\n",
    "        self.conv2d_2_enc = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=2)\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.batch_norm = nn.BatchNorm1d\n",
    "        new_h = conv2d_size_out(conv2d_size_out(36, kernel_size=3, stride=2), kernel_size=3, stride=2)\n",
    "        new_w = conv2d_size_out(conv2d_size_out(69, kernel_size=3, stride=2), kernel_size=3, stride=2)\n",
    "        self.dense_enc = nn.Linear(in_features=new_h * new_w * 64, out_features=self.latent_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1_enc(x)\n",
    "        x = self.lrelu(x)\n",
    "        x = self.batch_norm(x)\n",
    "\n",
    "        x = self.conv2d_2_enc(x)\n",
    "        x = self.lrelu(x)\n",
    "        x = self.batch_norm(x)\n",
    "        \n",
    "        self.vol_size = np.array(x.shape)\n",
    "        x = torch.flatten(x)\n",
    "        x = self.dense_enc(x)\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        new_h = conv2d_size_out(conv2d_size_out(36, kernel_size=3, stride=2), kernel_size=3, stride=2)\n",
    "        new_w = conv2d_size_out(conv2d_size_out(69, kernel_size=3, stride=2), kernel_size=3, stride=2)\n",
    "        self.dense_dec = nn.Linear(in_features=self.latent_dim, out_features=new_h * new_w * 64)\n",
    "        self.convtranspose2d_1_dec = nn.ConvTranspose2d(in_channels=new_h * new_w * 64, out_channels=64, kernel_size=(3, 3), stride=2)\n",
    "        self.convtranspose2d_2_dec = nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=(3, 3), stride=2)  \n",
    "        self.convtranspose2d_3_dec = nn.ConvTranspose2d(in_channels=32, out_channels=1, kernel_size=(3, 3))  \n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.batch_norm = nn.BatchNorm1d\n",
    "        self.sigmoid = nn.Sigmoid\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense_dec(x)\n",
    "        x = torch.reshape(self.vol_size)\n",
    "\n",
    "        x = self.convtranspose2d_1_dec(x)\n",
    "        x = self.lrelu(x)\n",
    "        x = self.batch_norm(x)\n",
    "\n",
    "        x = self.convtranspose2d_2_dec(x)\n",
    "        x = self.lrelu(x)\n",
    "        x = self.batch_norm(x)\n",
    "\n",
    "        x = self.convtranspose2d_3_dec(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from show_loss import show_loss\n",
    "from test import test\n",
    "from get_test_stats import get_test_stats\n",
    "from show_test_data import show_test_data\n",
    "from sklearn import metrics\n",
    "from parameters import Stats\n",
    "from IPython.display import clear_output\n",
    "from config_reader import Config\n",
    "\n",
    "'''\n",
    "Train the network on given data.\n",
    "\n",
    "nn           - Network to train.\n",
    "batch_size   - Batch size to apply to data.\n",
    "num_epochs   - How many epochs to train for.\n",
    "train_data   - Data to train on.\n",
    "labels_train - Labels for train_data.\n",
    "loss_func    - Loss function.\n",
    "optimizer    - Optimizer for gradients.\n",
    "draw         - Whether to display loss dynamics.\n",
    "step_test    - Whether to test on test data after each epoch.\n",
    "args         - test data and test labels.\n",
    "\n",
    "It's not recommended to use 'draw' and 'step_test' at the same time.\n",
    "'''\n",
    "def train_epoch(encoder, decoder, batch_size, train_data, loss_func, optimizer, device):  \n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    train_loss = []\n",
    "\n",
    "    iters = int(train_data.shape[2] / batch_size)\n",
    "    for i in range(iters): \n",
    "        # Move tensor to the proper device\n",
    "        image_batch = train_data[:, :, i:i + batch_size]\n",
    "        image_batch = image_batch.to(device)\n",
    "        \n",
    "        # Encode data\n",
    "        encoded_data = encoder(image_batch)\n",
    "        # Decode data\n",
    "        decoded_data = decoder(encoded_data)\n",
    "        # Evaluate loss\n",
    "        loss = loss_func(decoded_data, image_batch)\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print batch loss\n",
    "        print('\\t partial train loss (single batch): %f' % (loss.data))\n",
    "        train_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    return np.mean(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing function\n",
    "def test_epoch(encoder, decoder, test_data, device, loss_func):\n",
    "    # Set evaluation mode for encoder and decoder\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.no_grad(): # No need to track the gradients\n",
    "        # Define the lists to store the outputs for each batch\n",
    "        conc_out = []\n",
    "        conc_label = []\n",
    "        for i in range(test_data.shape[2]):\n",
    "            # Move tensor to the proper device\n",
    "            image_batch = test_data[i].to(device)\n",
    "            # Encode data\n",
    "            encoded_data = encoder(image_batch)\n",
    "            # Decode data\n",
    "            decoded_data = decoder(encoded_data)\n",
    "            # Append the network output and the original image to the lists\n",
    "            conc_out.append(decoded_data.cpu())\n",
    "            conc_label.append(image_batch.cpu())\n",
    "        # Create a single tensor with all the values in the lists\n",
    "        conc_out = torch.cat(conc_out)\n",
    "        conc_label = torch.cat(conc_label) \n",
    "        # Evaluate global loss\n",
    "        val_loss = loss_func(conc_out, conc_label)\n",
    "    return val_loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ae_outputs(encoder, decoder, n=10):\n",
    "    plt.figure(figsize=(16,4.5))\n",
    "    targets = test_data.targets.numpy()\n",
    "    t_idx = {i : np.where(targets==i)[0][0] for i in range(n)}\n",
    "    for i in range(n):\n",
    "      ax = plt.subplot(2,n,i+1)\n",
    "      img = test_data[t_idx[i]][0].unsqueeze(0).to(device)\n",
    "      encoder.eval()\n",
    "      decoder.eval()\n",
    "      with torch.no_grad():\n",
    "         rec_img  = decoder(encoder(img))\n",
    "      plt.imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "        ax.set_title('Original images')\n",
    "      ax = plt.subplot(2, n, i + 1 + n)\n",
    "      plt.imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')  \n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "         ax.set_title('Reconstructed images')\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cpu\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "lr = 1e-4\n",
    "batch_size = 128\n",
    "latent_dim = 8\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder = Encoder(latent_dim=latent_dim)\n",
    "decoder = Decoder(latent_dim=latent_dim)\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "optimizer = optim.Adam(params_to_optimize, lr=lr, weight_decay=lr/num_epochs)\n",
    "criterion = nn.MSELoss()\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "print(f'Selected device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 1, 3, 3], expected input[1, 36, 69, 128] to have 1 channels, but got 36 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\Tikhomirov_Sergei\\climate\\src\\Anomaly.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m diz_loss \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m'\u001b[39m:[],\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m:[]}\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m    train_loss \u001b[39m=\u001b[39m train_epoch(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m       encoder\u001b[39m=\u001b[39;49mencoder,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m       decoder\u001b[39m=\u001b[39;49mdecoder,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m       batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m       train_data\u001b[39m=\u001b[39;49mtrain_data,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m       loss_func\u001b[39m=\u001b[39;49mcriterion,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m       optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m       device\u001b[39m=\u001b[39;49mdevice)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m    val_loss \u001b[39m=\u001b[39m test_epoch(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m       encoder\u001b[39m=\u001b[39mencoder,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m       decoder\u001b[39m=\u001b[39mdecoder,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m       test_data\u001b[39m=\u001b[39mtest_data,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m       device\u001b[39m=\u001b[39mdevice,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m       loss_func\u001b[39m=\u001b[39mcriterion)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m    \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m EPOCH \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m train loss \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m val loss \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, num_epochs,train_loss,val_loss))\n",
      "\u001b[1;32md:\\Tikhomirov_Sergei\\climate\\src\\Anomaly.ipynb Cell 9\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(encoder, decoder, batch_size, train_data, loss_func, optimizer, device)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m image_batch \u001b[39m=\u001b[39m image_batch\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Encode data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m encoded_data \u001b[39m=\u001b[39m encoder(image_batch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# Decode data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m decoded_data \u001b[39m=\u001b[39m decoder(encoded_data)\n",
      "File \u001b[1;32mc:\\Users\\mike_live\\.conda\\envs\\ml_climate\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32md:\\Tikhomirov_Sergei\\climate\\src\\Anomaly.ipynb Cell 9\u001b[0m in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2d_1_enc(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlrelu(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_norm(x)\n",
      "File \u001b[1;32mc:\\Users\\mike_live\\.conda\\envs\\ml_climate\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mike_live\\.conda\\envs\\ml_climate\\lib\\site-packages\\torch\\nn\\modules\\conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\mike_live\\.conda\\envs\\ml_climate\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 1, 3, 3], expected input[1, 36, 69, 128] to have 1 channels, but got 36 channels instead"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "diz_loss = {'train_loss':[],'val_loss':[]}\n",
    "for epoch in range(num_epochs):\n",
    "   train_loss = train_epoch(\n",
    "      encoder=encoder,\n",
    "      decoder=decoder,\n",
    "      batch_size=batch_size,\n",
    "      train_data=train_data,\n",
    "      loss_func=criterion,\n",
    "      optimizer=optimizer,\n",
    "      device=device)\n",
    "   \n",
    "   val_loss = test_epoch(\n",
    "      encoder=encoder,\n",
    "      decoder=decoder,\n",
    "      test_data=test_data,\n",
    "      device=device,\n",
    "      loss_func=criterion)\n",
    "   print('\\n EPOCH {}/{} \\t train loss {} \\t val loss {}'.format(epoch + 1, num_epochs,train_loss,val_loss))\n",
    "   diz_loss['train_loss'].append(train_loss)\n",
    "   diz_loss['val_loss'].append(val_loss)\n",
    "   plot_ae_outputs(encoder,decoder,n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_climate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
