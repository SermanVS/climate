{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import copy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from config_reader import Config\n",
    "from read_data import read_data\n",
    "from preproc_data import *\n",
    "from label_data import label_data\n",
    "from split_data import split_data\n",
    "from detection import *\n",
    "from pathlib import Path\n",
    "from size_out import conv2d_size_out\n",
    "\n",
    "cfg = Config()\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone_events, data = read_data(path='../data')\n",
    "# Consider renaming first variable\n",
    "cyclone_events_data, data, metrics = preproc_data(cyclone_events, metrics=data)\n",
    "labels, events = label_data(cyclone_events_data.ce2)\n",
    "no_cyclone_data = cyclone_events_data.ce2[:, :, labels == 0]\n",
    "\n",
    "train_data = no_cyclone_data\n",
    "test_data = cyclone_events_data.ce2\n",
    "\n",
    "train_data = torch.tensor(no_cyclone_data, dtype=torch.double)\n",
    "test_data = torch.tensor(cyclone_events_data.ce2, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = \"Encoder-decoder that tries to catch anomalies.\"\n",
    "filename = \"Anomaly.ipynb\"\n",
    "network_name = filename.split('.')[0]\n",
    "comment = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.conv2d_1_enc = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=2)\n",
    "        self.conv2d_2_enc = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=2)\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.2)\n",
    "        #self.batch_norm = nn.BatchNorm2d()\n",
    "        new_h = conv2d_size_out(conv2d_size_out(36, kernel_size=3, stride=2), kernel_size=3, stride=2)\n",
    "        new_w = conv2d_size_out(conv2d_size_out(69, kernel_size=3, stride=2), kernel_size=3, stride=2)\n",
    "        self.dense_enc = nn.Linear(in_features=new_h * new_w * 64, out_features=self.latent_dim)\n",
    "        self.flatten = nn.Flatten()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print(f\"Encoder input shape: {x.shape}\")\n",
    "        x = self.conv2d_1_enc(x)\n",
    "        #print(f\"Encoder after conv2d_1: {x.shape}\")\n",
    "        x = self.lrelu(x)\n",
    "        #print(f\"Encoder after lrelu: {x.shape}\")\n",
    "        #x = self.batch_norm(x)\n",
    "        #print(f\"Encoder after batch_norm: {x.shape}\")\n",
    "        x = self.conv2d_2_enc(x)\n",
    "        #print(f\"Encoder after conv2d_2: {x.shape}\")\n",
    "        x = self.lrelu(x)\n",
    "        #x = self.batch_norm(x)\n",
    "        #print(f\"Encoder after batch_norm: {x.shape}\")\n",
    "        # [128, 64, 8, 16]\n",
    "        self.vol_size = np.array(x.shape)\n",
    "        x = self.flatten(x)\n",
    "        #print(f\"Encoder after flatten: {x.shape}\")\n",
    "        x = self.dense_enc(x)\n",
    "        #print(f\"Encoder after dense: {x.shape}\")\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        new_h = conv2d_size_out(conv2d_size_out(36, kernel_size=3, stride=2), kernel_size=3, stride=2)\n",
    "        new_w = conv2d_size_out(conv2d_size_out(69, kernel_size=3, stride=2), kernel_size=3, stride=2)\n",
    "        self.dense_dec = nn.Linear(in_features=self.latent_dim, out_features=new_h * new_w * 64)\n",
    "        self.convtranspose2d_1_dec = nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=(3, 3), stride=2, output_padding=(0, 1))\n",
    "        self.convtranspose2d_3_dec = nn.ConvTranspose2d(in_channels=32, out_channels=1, kernel_size=(3, 3), stride=2, output_padding=(1, 0))  \n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.2)\n",
    "        #self.batch_norm = nn.BatchNorm2d()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(f\"Decoder input size: {x.shape}\")\n",
    "        x = self.dense_dec(x)\n",
    "        #print(f\"Decoder after dense: {x.shape}\")\n",
    "        x = torch.reshape(x, (128, 64, 8, 16))\n",
    "        #print(f\"Decoder after reshape: {x.shape}\")\n",
    "        x = self.convtranspose2d_1_dec(x)\n",
    "        #print(f\"Decoder after convtranspose2d_1: {x.shape}\")\n",
    "        x = self.lrelu(x)\n",
    "        #x = self.batch_norm(x)\n",
    "        #print(f\"Decoder after batch_norm: {x.shape}\")\n",
    "        x = self.convtranspose2d_3_dec(x)\n",
    "        #print(f\"Decoder after convtranspose2d_3: {x.shape}\")\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from show_loss import show_loss\n",
    "from test import test\n",
    "from get_test_stats import get_test_stats\n",
    "from show_test_data import show_test_data\n",
    "from sklearn import metrics\n",
    "from parameters import Stats\n",
    "from IPython.display import clear_output\n",
    "from config_reader import Config\n",
    "\n",
    "'''\n",
    "Train the network on given data.\n",
    "\n",
    "nn           - Network to train.\n",
    "batch_size   - Batch size to apply to data.\n",
    "num_epochs   - How many epochs to train for.\n",
    "train_data   - Data to train on.\n",
    "labels_train - Labels for train_data.\n",
    "loss_func    - Loss function.\n",
    "optimizer    - Optimizer for gradients.\n",
    "draw         - Whether to display loss dynamics.\n",
    "step_test    - Whether to test on test data after each epoch.\n",
    "args         - test data and test labels.\n",
    "\n",
    "It's not recommended to use 'draw' and 'step_test' at the same time.\n",
    "'''\n",
    "def train_epoch(encoder, decoder, batch_size, train_data, loss_func, optimizer, device):  \n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    train_loss = []\n",
    "\n",
    "    encoder.double()\n",
    "    decoder.double()\n",
    "\n",
    "    iters = int(train_data.shape[2] / batch_size)\n",
    "    for i in tqdm(range(iters)): \n",
    "        # Move tensor to the proper device\n",
    "        image_batch = train_data[:, :, i:i + batch_size]\n",
    "        image_batch = image_batch.to(device)\n",
    "        image_batch = torch.unsqueeze(image_batch, 0)\n",
    "        image_batch = image_batch.reshape(image_batch.shape[-1], image_batch.shape[0], image_batch.shape[1], image_batch.shape[2])\n",
    "        # Encode data\n",
    "        encoded_data = encoder(image_batch)\n",
    "        # Decode data\n",
    "        decoded_data = decoder(encoded_data)\n",
    "        # Evaluate loss\n",
    "        loss = loss_func(decoded_data, image_batch)\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print batch loss\n",
    "        print('\\t partial train loss (single batch): %f' % (loss.data))\n",
    "        train_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    return np.mean(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing function\n",
    "def test_epoch(encoder, decoder, test_data, device, loss_func):\n",
    "    # Set evaluation mode for encoder and decoder\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    encoder.double()\n",
    "    decoder.double()\n",
    "    with torch.no_grad(): # No need to track the gradients\n",
    "        # Define the lists to store the outputs for each batch\n",
    "        conc_out = []\n",
    "        conc_label = []\n",
    "        for i in tqdm(range(test_data.shape[2])):\n",
    "            # Move tensor to the proper device\n",
    "            image_batch = test_data[:, :, i].to(device)\n",
    "            image_batch = torch.unsqueeze(image_batch, 0)\n",
    "            print(image_batch.shape)\n",
    "            # Encode data\n",
    "            encoded_data = encoder(image_batch)\n",
    "            # Decode data\n",
    "            decoded_data = decoder(encoded_data)\n",
    "            # Append the network output and the original image to the lists\n",
    "            conc_out.append(decoded_data.cpu())\n",
    "            conc_label.append(image_batch.cpu())\n",
    "        # Create a single tensor with all the values in the lists\n",
    "        conc_out = torch.cat(conc_out)\n",
    "        conc_label = torch.cat(conc_label) \n",
    "        # Evaluate global loss\n",
    "        val_loss = loss_func(conc_out, conc_label)\n",
    "    return val_loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ae_outputs(encoder, decoder, n=10):\n",
    "    plt.figure(figsize=(16,4.5))\n",
    "    targets = test_data.targets.numpy()\n",
    "    t_idx = {i : np.where(targets==i)[0][0] for i in range(n)}\n",
    "    for i in range(n):\n",
    "      ax = plt.subplot(2,n,i+1)\n",
    "      img = test_data[t_idx[i]][0].unsqueeze(0).to(device)\n",
    "      encoder.eval()\n",
    "      decoder.eval()\n",
    "      with torch.no_grad():\n",
    "         rec_img  = decoder(encoder(img))\n",
    "      plt.imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "        ax.set_title('Original images')\n",
    "      ax = plt.subplot(2, n, i + 1 + n)\n",
    "      plt.imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')  \n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "         ax.set_title('Reconstructed images')\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cpu\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "lr = 1e-4\n",
    "batch_size = 128\n",
    "latent_dim = 8\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder = Encoder(latent_dim=latent_dim)\n",
    "decoder = Decoder(latent_dim=latent_dim)\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "optimizer = optim.Adam(params_to_optimize, lr=lr, weight_decay=lr/num_epochs)\n",
    "criterion = nn.MSELoss()\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "print(f'Selected device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36, 69, 104350])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Tikhomirov_Sergei\\climate\\src\\Anomaly.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m diz_loss \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m'\u001b[39m:[],\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m:[]}\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m    train_loss \u001b[39m=\u001b[39m train_epoch(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m       encoder\u001b[39m=\u001b[39;49mencoder,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m       decoder\u001b[39m=\u001b[39;49mdecoder,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m       batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m       train_data\u001b[39m=\u001b[39;49mtrain_data[:, :, \u001b[39m1280\u001b[39;49m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m       loss_func\u001b[39m=\u001b[39;49mcriterion,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m       optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m       device\u001b[39m=\u001b[39;49mdevice)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m    val_loss \u001b[39m=\u001b[39m test_epoch(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m       encoder\u001b[39m=\u001b[39mencoder,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m       decoder\u001b[39m=\u001b[39mdecoder,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m       test_data\u001b[39m=\u001b[39mtest_data,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m       device\u001b[39m=\u001b[39mdevice,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m       loss_func\u001b[39m=\u001b[39mcriterion)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m    \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m EPOCH \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m train loss \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m val loss \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, num_epochs,train_loss,val_loss))\n",
      "\u001b[1;32md:\\Tikhomirov_Sergei\\climate\\src\\Anomaly.ipynb Cell 10\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(encoder, decoder, batch_size, train_data, loss_func, optimizer, device)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m encoder\u001b[39m.\u001b[39mdouble()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m decoder\u001b[39m.\u001b[39mdouble()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m iters \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(train_data\u001b[39m.\u001b[39;49mshape[\u001b[39m2\u001b[39;49m] \u001b[39m/\u001b[39m batch_size)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(iters)): \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     \u001b[39m# Move tensor to the proper device\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/Anomaly.ipynb#X11sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     image_batch \u001b[39m=\u001b[39m train_data[:, :, i:i \u001b[39m+\u001b[39m batch_size]\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "diz_loss = {'train_loss':[],'val_loss':[]}\n",
    "for epoch in range(num_epochs):\n",
    "   train_loss = train_epoch(\n",
    "      encoder=encoder,\n",
    "      decoder=decoder,\n",
    "      batch_size=batch_size,\n",
    "      train_data=train_data,\n",
    "      loss_func=criterion,\n",
    "      optimizer=optimizer,\n",
    "      device=device)\n",
    "   \n",
    "   val_loss = test_epoch(\n",
    "      encoder=encoder,\n",
    "      decoder=decoder,\n",
    "      test_data=test_data,\n",
    "      device=device,\n",
    "      loss_func=criterion)\n",
    "   print('\\n EPOCH {}/{} \\t train loss {} \\t val loss {}'.format(epoch + 1, num_epochs,train_loss,val_loss))\n",
    "   diz_loss['train_loss'].append(train_loss)\n",
    "   diz_loss['val_loss'].append(val_loss)\n",
    "   plot_ae_outputs(encoder,decoder,n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_climate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
