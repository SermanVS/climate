{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import copy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from config_reader import Config\n",
    "from read_data import read_data\n",
    "from preproc_data import *\n",
    "from label_data import label_data\n",
    "from split_data import split_data\n",
    "from detection import *\n",
    "\n",
    "cfg = Config()\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone_events, data = read_data(path='../data')\n",
    "# Consider renaming first variable\n",
    "cyclone_events_data, data, metrics = preproc_data(cyclone_events, metrics=data)\n",
    "labels, events = label_data(cyclone_events_data.ce2)\n",
    "train_data, test_data, labels_train, labels_test, train_id, test_id = split_data(data, labels, ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train_old = labels_train\n",
    "labels_test_old = labels_test\n",
    "labels_train = [[item, 1 - item] for item in labels_train]\n",
    "labels_test = [[item, 1 - item] for item in labels_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = \"ResNet18_2\"\n",
    "filename = \"ResNet18_2.ipynb\"\n",
    "network_name = filename.split('.')[0]\n",
    "comment = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from show_test_data import show_test_data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from config_reader import Config\n",
    "from sigma import sigma\n",
    "import pandas as pd\n",
    "\n",
    "def get_start_ticks(labels_test):\n",
    "    labels_test = np.array(labels_test)\n",
    "    start_ticks = []\n",
    "    for i in range(len(labels_test) - 1):\n",
    "        if (labels_test[i] == 0 and labels_test[i+1] == 1):\n",
    "            start_ticks.append(i+1)\n",
    "    return np.array(start_ticks)\n",
    "\n",
    "def predicted_event_id(tick, start_ticks):\n",
    "    idx = (np.abs(start_ticks - tick)).argmin()\n",
    "    return idx\n",
    "\n",
    "def fill_preicted_events(predicted_events, start_ticks, labels_test):\n",
    "    cfg = Config()\n",
    "    #res = np.zeros(shape=len(labels_test), dtype=int)\n",
    "    res = [0] * len(labels_test)\n",
    "    for k, pr in enumerate(predicted_events):\n",
    "        if pr == 1:\n",
    "            for i in range(start_ticks[k], start_ticks[k] + cfg.w):\n",
    "                res[i] = 1\n",
    "\n",
    "    res = indices(res, 1)\n",
    "    return np.array(res, dtype=int)\n",
    "\n",
    "def indices(lst, item):\n",
    "    return [i for i, x in enumerate(lst) if x == item]\n",
    "\n",
    "\n",
    "def test(nn, test_data, labels_test):\n",
    "    # Test the model\n",
    "    cfg = Config()\n",
    "    nn.eval()    \n",
    "    sigmas = []\n",
    "    tp_ids = []\n",
    "    fp_ids = []\n",
    "    fn_ids = []\n",
    "    tn_ids = []\n",
    "\n",
    "    if cfg.mode == 'predict':\n",
    "        predicted = np.zeros(shape=test_data.shape[2])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        tn = 0\n",
    "        for i in range(test_data.shape[2]):\n",
    "            if (labels_test[i] == 2):\n",
    "                continue\n",
    "            image = test_data[:, :, i]\n",
    "            label = labels_test[i]\n",
    "            \n",
    "            image = image.unsqueeze(0) \n",
    "            image = image.unsqueeze(0) \n",
    "            \n",
    "            test_output = nn(image)\n",
    "            #arg = test_output.item()\n",
    "            #sig = sigma(arg)\n",
    "            #sigmas.append(sig)\n",
    "            \n",
    "            _, pred_y = torch.max(test_output.data, 1)\n",
    "            # print(f\"pred_y {pred_y}\")\n",
    "            # print(f\"label {label}\")\n",
    "            #print(sig)\n",
    "            # 0 - 1 when cyclone is present\n",
    "            if (pred_y == label and label == 1):\n",
    "                tp += 1\n",
    "                tp_ids.append(i)\n",
    "            # 1 - 0 when no cyclone is present\n",
    "            elif (pred_y == label and label == 0):\n",
    "                tn += 1\n",
    "                tn_ids.append(i)\n",
    "            # 0 - 1 when no cyclone is present\n",
    "            elif (pred_y != label and label == 1):\n",
    "                fn += 1\n",
    "                fn_ids.append(i)\n",
    "            # 1 - 0 when cyclone is present\n",
    "            elif (pred_y != label and label == 0):\n",
    "                fp += 1\n",
    "                fp_ids.append(i)\n",
    "            pass   \n",
    "        pass\n",
    "    \n",
    "    if cfg.mode == 'predict':\n",
    "        predicted[tp_ids] = 1\n",
    "        event_start_ticks = get_start_ticks(labels_test)\n",
    "        predicted_events = np.zeros(shape=len(event_start_ticks))\n",
    "\n",
    "        for item in tp_ids:\n",
    "            predicted_event = predicted_event_id(item, event_start_ticks)\n",
    "            predicted_events[predicted_event] = 1\n",
    "\n",
    "        tp_ids = fill_preicted_events(predicted_events, event_start_ticks, labels_test)\n",
    "\n",
    "        tp = predicted_events.sum()\n",
    "        fn = len(event_start_ticks) - tp\n",
    "    \n",
    "        fp = fp // cfg.w\n",
    "        tn = tn // cfg.w\n",
    "    return tp, tn, fp, fn, sigmas, (tp_ids, fp_ids, fn_ids, tn_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from show_loss import show_loss\n",
    "from get_test_stats import get_test_stats\n",
    "from show_test_data import show_test_data\n",
    "from sklearn import metrics\n",
    "from parameters import Stats\n",
    "from IPython.display import clear_output\n",
    "from config_reader import Config\n",
    "\n",
    "'''\n",
    "Train the network on given data.\n",
    "\n",
    "nn           - Network to train.\n",
    "batch_size   - Batch size to apply to data.\n",
    "num_epochs   - How many epochs to train for.\n",
    "train_data   - Data to train on.\n",
    "labels_train - Labels for train_data.\n",
    "loss_func    - Loss function.\n",
    "optimizer    - Optimizer for gradients.\n",
    "draw         - Whether to display loss dynamics.\n",
    "step_test    - Whether to test on test data after each epoch.\n",
    "args         - test data and test labels.\n",
    "\n",
    "It's not recommended to use 'draw' and 'step_test' at the same time.\n",
    "'''\n",
    "def train(cnn, batch_size, num_epochs, train_data, labels_train_pre, loss_func, optimizer, args, draw=False, step_test=False, preload=False):\n",
    "    if preload:\n",
    "        try:\n",
    "            cnn = models.resnet50(weights=models.ResNet50_Weights) \n",
    "            cnn.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "            cnn.fc = nn.Linear(in_features=2048, out_features=2, bias=True)\n",
    "            cnn.load_state_dict(torch.load(\"resnet50_full.pt\"))\n",
    "        except:\n",
    "            cnn = models.resnet50(weights=models.ResNet50_Weights) \n",
    "            cnn.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "            cnn.fc = nn.Linear(in_features=2048, out_features=2, bias=True) \n",
    "    cnn.train()\n",
    "    cnn = cnn.double()\n",
    "    loss_vals = []\n",
    "    epoch_loss = []\n",
    "\n",
    "    labels_train = torch.tensor([(0 if i == 2 else i) for i in labels_train_pre])\n",
    "    \n",
    "    test_stats_list = []\n",
    "    train_stats_list = []\n",
    "\n",
    "    tprs_test = []\n",
    "    fprs_test = []\n",
    "    tprs_train  = []\n",
    "    fprs_train = []\n",
    "\n",
    "    fprs_test.append(0)\n",
    "    tprs_test.append(0)\n",
    "    fprs_train.append(0)\n",
    "    tprs_train.append(0)\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        running_loss = 0.0\n",
    "        iters = int(train_data.shape[2] / batch_size)\n",
    "        for i in range(iters):\n",
    "            images = train_data[:, :, i:i + batch_size]\n",
    "            labels = labels_train[i:i + batch_size]        \n",
    "            \n",
    "            b_x = images  \n",
    "            # Change to Double if doesn't work\n",
    "            b_y = labels.double()\n",
    "            b_x = b_x.reshape((batch_size, 1, 36, 69))          \n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            output = cnn(b_x)\n",
    "            #print(output)\n",
    "            loss = loss_func(input=output, target=b_y)   \n",
    "            epoch_loss.append(loss.item())\n",
    "            running_loss += loss.item() * batch_size\n",
    "            \n",
    "            if draw:\n",
    "                show_loss(epoch_loss, loss_vals)\n",
    "            elif (draw and i != 0 and i % 100 == 0 and not step_test and epoch > 0):\n",
    "                show_loss(epoch_loss, loss_vals, clear_after=False)\n",
    "                show_test_data(test_stats_list, train_stats_list)\n",
    "                clear_output(True)\n",
    "            elif (draw and i != 0 and i % 100 == 0 and not step_test and epoch == 0):\n",
    "                show_loss(epoch_loss, loss_vals)\n",
    "            \n",
    "            loss.backward()                           \n",
    "            optimizer.step()  \n",
    "\n",
    "        if (step_test):\n",
    "            tp, tn, fp, fn, sigmas, _ = test(cnn, args[0], args[1])  \n",
    "            test_stats = get_test_stats(args[0].shape[2], tp, tn, fp, fn, sigmas)          \n",
    "            test_stats_list.append(test_stats)          \n",
    "\n",
    "            tp, tn, fp, fn, sigmas, _ = test(cnn, train_data, labels_train_pre)  \n",
    "            train_stats = get_test_stats(args[0].shape[2], tp, tn, fp, fn, sigmas)       \n",
    "            train_stats_list.append(train_stats)\n",
    "\n",
    "            show_test_data(test_stats_list, train_stats_list)\n",
    "            cnn.train()\n",
    "        pass\n",
    "        torch.save(cnn, \"resnet50_full.pt\")\n",
    "        loss_vals.append(running_loss / train_data.shape[2])\n",
    "        \n",
    "    tprs_test += [item.tpr for item in test_stats_list]\n",
    "    tprs_train += [item.tpr for item in train_stats_list]\n",
    "    fprs_test += [item.fpr for item in test_stats_list]\n",
    "    fprs_train += [item.fpr for item in train_stats_list]\n",
    "\n",
    "    fprs_test.append(1)\n",
    "    tprs_test.append(1)\n",
    "    fprs_train.append(1)\n",
    "    tprs_train.append(1)\n",
    "\n",
    "    fprs_test, tprs_test = zip(*sorted(zip(fprs_test, tprs_test)))\n",
    "    fprs_train, tprs_train = zip(*sorted(zip(fprs_train, tprs_train)))\n",
    "\n",
    "    # sort by fpr\n",
    "    auc_test = metrics.auc(fprs_test, tprs_test)\n",
    "    auc_train = metrics.auc(fprs_train, tprs_train)\n",
    "    return auc_test, auc_train \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mike_live\\.conda\\envs\\ml_climate\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\mike_live/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b83aedebab44b3bd78b6a55078fd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 40\n",
    "batch_size = 24\n",
    "\n",
    "\n",
    "y = torch.tensor(list(labels_train_old))\n",
    "class_weights=class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y.numpy())\n",
    "class_weights=torch.tensor(class_weights, dtype=torch.double)\n",
    "\n",
    "cnn = models.resnet50(weights=models.ResNet50_Weights)\n",
    "cnn.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "cnn.fc = nn.Linear(in_features=2048, out_features=2, bias=True)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights[1]/class_weights[0], reduction='mean') \n",
    "optimizer = optim.Adam(cnn.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc095896b3af4d54b5b6f30569189677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (24x2048 and 512x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\Tikhomirov_Sergei\\climate\\src\\ResNet18 copy.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/ResNet18%20copy.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m auc_test, auc_train \u001b[39m=\u001b[39m train(cnn\u001b[39m=\u001b[39;49mcnn, batch_size\u001b[39m=\u001b[39;49mbatch_size, num_epochs\u001b[39m=\u001b[39;49mnum_epochs, train_data\u001b[39m=\u001b[39;49mtrain_data, labels_train_pre\u001b[39m=\u001b[39;49mlabels_train, loss_func\u001b[39m=\u001b[39;49mcriterion, optimizer\u001b[39m=\u001b[39;49moptimizer, args\u001b[39m=\u001b[39;49m(test_data, labels_test), draw\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, step_test\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, preload\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[1;32md:\\Tikhomirov_Sergei\\climate\\src\\ResNet18 copy.ipynb Cell 8\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(cnn, batch_size, num_epochs, train_data, labels_train_pre, loss_func, optimizer, args, draw, step_test, preload)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/ResNet18%20copy.ipynb#X10sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m b_x \u001b[39m=\u001b[39m b_x\u001b[39m.\u001b[39mreshape((batch_size, \u001b[39m1\u001b[39m, \u001b[39m36\u001b[39m, \u001b[39m69\u001b[39m))          \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/ResNet18%20copy.ipynb#X10sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/ResNet18%20copy.ipynb#X10sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m output \u001b[39m=\u001b[39m cnn(b_x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/ResNet18%20copy.ipynb#X10sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39m#print(output)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tikhomirov_Sergei/climate/src/ResNet18%20copy.ipynb#X10sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_func(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39moutput, target\u001b[39m=\u001b[39mb_y)   \n",
      "File \u001b[1;32mc:\\Users\\mike_live\\.conda\\envs\\ml_climate\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mike_live\\.conda\\envs\\ml_climate\\lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[1;32mc:\\Users\\mike_live\\.conda\\envs\\ml_climate\\lib\\site-packages\\torchvision\\models\\resnet.py:280\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    278\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[0;32m    279\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc(x)\n\u001b[0;32m    282\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\mike_live\\.conda\\envs\\ml_climate\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mike_live\\.conda\\envs\\ml_climate\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (24x2048 and 512x2)"
     ]
    }
   ],
   "source": [
    "auc_test, auc_train = train(cnn=cnn, batch_size=batch_size, num_epochs=num_epochs, train_data=train_data, labels_train_pre=labels_train, loss_func=criterion, optimizer=optimizer, args=(test_data, labels_test), draw=True, step_test=False, preload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlunn2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7906f88924d0acbcc878920ce9dbcc77a020e1b0135b8245f9ac081820afa623"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
