{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70e0c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3af38069",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone_events = np.load('data/ERA5/ERA5_MSL_1982_2020_3h_0.75/cyclones_events.npz')\n",
    "closeness_w = np.load('H:/Climate/data/ERA5/ERA5_MSL_1982_2020_3h_0.75/metrics_corr_land_masked_and_preproc_window_2d_delay_0d/diff_metrics/network_metrics/closeness_w.npy')\n",
    "degree_w = np.load('H:/Climate/data/ERA5/ERA5_MSL_1982_2020_3h_0.75/metrics_corr_land_masked_and_preproc_window_2d_delay_0d/diff_metrics/network_metrics/degree_w.npy')\n",
    "EVC_w = np.load('H:/Climate/data/ERA5/ERA5_MSL_1982_2020_3h_0.75/metrics_corr_land_masked_and_preproc_window_2d_delay_0d/diff_metrics/network_metrics/EVC_w.npy')\n",
    "GCC_w = np.load('H:/Climate/data/ERA5/ERA5_MSL_1982_2020_3h_0.75/metrics_corr_land_masked_and_preproc_window_2d_delay_0d/diff_metrics/network_metrics/GCC_w.npy')\n",
    "LCC_w = np.load('H:/Climate/data/ERA5/ERA5_MSL_1982_2020_3h_0.75/metrics_corr_land_masked_and_preproc_window_2d_delay_0d/diff_metrics/network_metrics/LCC_w.npy')\n",
    "MSLP_preproc = np.load('H:/Climate/data/ERA5/ERA5_MSL_1982_2020_3h_0.75/metrics_corr_land_masked_and_preproc_window_2d_delay_0d/diff_metrics/input_data/MSLP_preproc.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56c42c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone_events_2 = cyclone_events[cyclone_events.files[0]]\n",
    "cyclone_events_4 = cyclone_events[cyclone_events.files[1]]\n",
    "cyclone_events_6 = cyclone_events[cyclone_events.files[2]]\n",
    "cyclone_events_8 = cyclone_events[cyclone_events.files[3]]\n",
    "cyclone_events_10 = cyclone_events[cyclone_events.files[4]]\n",
    "cyclone_events_12 = cyclone_events[cyclone_events.files[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91852abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 69, 113960)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyclone_events_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d46b1215",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSLP_preproc = np.reshape(MSLP_preproc, (36, 69, 113960))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe91f49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros(113960)\n",
    "\n",
    "for i in range(113960):\n",
    "    if len(cyclone_events_2[:, :, i][cyclone_events_2[:, :, i] != False]) > 0:\n",
    "        labels[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ea3fa579",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cyclone_occurances = []\n",
    "no_cyclone = []\n",
    "for i in range(113960):\n",
    "    if len(cyclone_events_2[:, :, i][cyclone_events_2[:, :, i] != False]) > 0:\n",
    "        cyclone_occurances.append(i)\n",
    "    else:\n",
    "        no_cyclone.append(i)\n",
    "        \n",
    "import random\n",
    "random.shuffle(cyclone_occurances)\n",
    "random.shuffle(no_cyclone)    \n",
    "\n",
    "f1 = open(\"shuffle_cyclone.csv\", \"w\")\n",
    "f2 = open(\"shuffle_no_cyclone.csv\", \"w\")\n",
    "[f1.write(str(item) + ',') for item in cyclone_occurances]\n",
    "[f2.write(str(item) + ',') for item in no_cyclone]\n",
    "f1.close()\n",
    "f2.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363862bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f961a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone_occurances = pd.read_csv(\"shuffle_cyclone.csv\", header=None).values[0]\n",
    "no_cyclone = pd.read_csv(\"shuffle_no_cyclone.csv\", header=None).values[0]\n",
    "\n",
    "cut_cyclone = int(0.8 * len(cyclone_occurances))\n",
    "cut_no_cyclone = int(0.8 * len(no_cyclone))\n",
    "\n",
    "train_id = cyclone_occurances[:cut_cyclone].astype(int)\n",
    "train_id = np.append(train_id, no_cyclone[:cut_no_cyclone].astype(int))\n",
    "\n",
    "test_id = cyclone_occurances[cut_cyclone:-1].astype(int) \n",
    "test_id = np.append(test_id, no_cyclone[cut_no_cyclone:-1].astype(int))\n",
    "\n",
    "train_data = torch.tensor(MSLP_preproc[:, :, train_id], dtype=torch.double)\n",
    "test_data = torch.tensor(MSLP_preproc[:, :, test_id], dtype=torch.double)\n",
    "\n",
    "labels_train = torch.tensor(labels[train_id])\n",
    "labels_test = torch.tensor(labels[test_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9104e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()        \n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=36,            \n",
    "                kernel_size=(3, 3),          ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(36, 72, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )        \n",
    "        \n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(72 * 36 * 69, 2)    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)        \n",
    "        \n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output, x    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6a6ce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "loss_func = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(cnn.parameters(), lr = 0.01)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3058579f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   0.0000,      nan,  ...,      nan,      nan,      nan],\n",
       "        [     nan,      nan,      nan,  ...,      nan,      nan,      nan],\n",
       "        [     nan,      nan,      nan,  ...,      nan,      nan,      nan],\n",
       "        ...,\n",
       "        [     nan,      nan,  -8.0249,  ..., -64.3642, -78.0519,      nan],\n",
       "        [     nan,      nan,  -9.1256,  ...,  -3.7856, -73.8378,      nan],\n",
       "        [     nan,      nan,  -9.8328,  ...,      nan, -26.1540, -17.9396]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "02352553",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\Users\\builder\\tkoch\\workspace\\pytorch\\pytorch_1647970138273\\work\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 38978755200 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 33>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [47]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(num_epochs, cnn, train_data, labels_train)\u001b[0m\n\u001b[0;32m     19\u001b[0m b_x \u001b[38;5;241m=\u001b[39m Variable(image)   \u001b[38;5;66;03m# batch x\u001b[39;00m\n\u001b[0;32m     20\u001b[0m b_y \u001b[38;5;241m=\u001b[39m Variable(label)   \u001b[38;5;66;03m# batch y\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_x\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]               \n\u001b[0;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(output, b_y)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# clear gradients for this training step   \u001b[39;00m\n",
      "File \u001b[1;32mG:\\Anaconda3\\envs\\mlunn2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     21\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m---> 22\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m        \n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# flatten the output of conv2 to (batch_size, 32 * 7 * 7)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)       \n",
      "File \u001b[1;32mG:\\Anaconda3\\envs\\mlunn2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mG:\\Anaconda3\\envs\\mlunn2\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mG:\\Anaconda3\\envs\\mlunn2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mG:\\Anaconda3\\envs\\mlunn2\\lib\\site-packages\\torch\\nn\\modules\\conv.py:446\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Anaconda3\\envs\\mlunn2\\lib\\site-packages\\torch\\nn\\modules\\conv.py:442\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    440\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    441\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\Users\\builder\\tkoch\\workspace\\pytorch\\pytorch_1647970138273\\work\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 38978755200 bytes."
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "def train(num_epochs, cnn, train_data, labels_train):  \n",
    "    cnn.train()\n",
    "    \n",
    "    cnn = cnn.double()\n",
    "        \n",
    "    # Train the model\n",
    "    batch_size = int(0.1 * train_data.shape[2])\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(10):\n",
    "            \n",
    "            image = train_data[:, :, (i * batch_size) : (i + 1) * batch_size]\n",
    "            label = labels_train[i*batch_size : (i+1) * batch_size]\n",
    "            \n",
    "            image = image.unsqueeze(1) \n",
    "            # gives batch data, normalize x when iterate train_loader\n",
    "            b_x = Variable(image)   # batch x\n",
    "            b_y = Variable(label)   # batch y\n",
    "            output = cnn(b_x)[0]               \n",
    "            loss = loss_func(output, b_y)\n",
    "\n",
    "            # clear gradients for this training step   \n",
    "            optimizer.zero_grad()           \n",
    "\n",
    "            # backpropagation, compute gradients \n",
    "            loss.backward()                # apply gradients             \n",
    "            optimizer.step()  \n",
    "        pass\n",
    "    pass\n",
    "\n",
    "train(num_epochs, cnn, train_data, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8c299b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
