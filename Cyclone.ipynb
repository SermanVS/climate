{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70e0c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3af38069",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone_events = np.load('data/ERA5/ERA5_MSL_1982_2020_3h_0.75/cyclones_events.npz')\n",
    "closeness_w = np.load('data/ERA5/ERA5_MSL_1982_2020_3h_0.75/metrics_corr_land_masked_and_preproc_window_2d_delay_0d/probability_for_metrics/diff_metrics/network_metrics/closeness_w.npy')\n",
    "degree_w = np.load('data/ERA5/ERA5_MSL_1982_2020_3h_0.75/metrics_corr_land_masked_and_preproc_window_2d_delay_0d/probability_for_metrics/diff_metrics/network_metrics/degree_w.npy')\n",
    "EVC_w = np.load('data/ERA5/ERA5_MSL_1982_2020_3h_0.75/metrics_corr_land_masked_and_preproc_window_2d_delay_0d/probability_for_metrics/diff_metrics/network_metrics/EVC_w.npy')\n",
    "LCC_w = np.load('data/ERA5/ERA5_MSL_1982_2020_3h_0.75/metrics_corr_land_masked_and_preproc_window_2d_delay_0d/probability_for_metrics/diff_metrics/network_metrics/LCC_w.npy')\n",
    "MSLP_preproc = np.load('data/ERA5/ERA5_MSL_1982_2020_3h_0.75/metrics_corr_land_masked_and_preproc_window_2d_delay_0d/probability_for_metrics/input_data/MSLP_preproc.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56c42c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone_events_2 = cyclone_events[cyclone_events.files[0]]\n",
    "cyclone_events_4 = cyclone_events[cyclone_events.files[1]]\n",
    "cyclone_events_6 = cyclone_events[cyclone_events.files[2]]\n",
    "cyclone_events_8 = cyclone_events[cyclone_events.files[3]]\n",
    "cyclone_events_10 = cyclone_events[cyclone_events.files[4]]\n",
    "cyclone_events_12 = cyclone_events[cyclone_events.files[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91852abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 69, 113960)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyclone_events_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d46b1215",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSLP_preproc = np.reshape(MSLP_preproc, (36, 69, 113960))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe91f49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros(113960)\n",
    "\n",
    "for i in range(113960):\n",
    "    if len(cyclone_events_2[:, :, i][cyclone_events_2[:, :, i] != False]) > 0:\n",
    "        labels[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea3fa579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncyclone_occurances = []\\nno_cyclone = []\\nfor i in range(113960):\\n    if len(cyclone_events_2[:, :, i][cyclone_events_2[:, :, i] != False]) > 0:\\n        cyclone_occurances.append(i)\\n    else:\\n        no_cyclone.append(i)\\n        \\nimport random\\nrandom.shuffle(cyclone_occurances)\\nrandom.shuffle(no_cyclone)    \\n\\nf1 = open(\"shuffle_cyclone.csv\", \"w\")\\nf2 = open(\"shuffle_no_cyclone.csv\", \"w\")\\n[f1.write(str(item) + \\',\\') for item in cyclone_occurances]\\n[f2.write(str(item) + \\',\\') for item in no_cyclone]\\nf1.close()\\nf2.close()\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cyclone_occurances = []\n",
    "no_cyclone = []\n",
    "for i in range(113960):\n",
    "    if len(cyclone_events_2[:, :, i][cyclone_events_2[:, :, i] != False]) > 0:\n",
    "        cyclone_occurances.append(i)\n",
    "    else:\n",
    "        no_cyclone.append(i)\n",
    "        \n",
    "import random\n",
    "random.shuffle(cyclone_occurances)\n",
    "random.shuffle(no_cyclone)    \n",
    "\n",
    "f1 = open(\"shuffle_cyclone.csv\", \"w\")\n",
    "f2 = open(\"shuffle_no_cyclone.csv\", \"w\")\n",
    "[f1.write(str(item) + ',') for item in cyclone_occurances]\n",
    "[f2.write(str(item) + ',') for item in no_cyclone]\n",
    "f1.close()\n",
    "f2.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "363862bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MSLP_preproc.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f961a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone_occurances = pd.read_csv(\"shuffle_cyclone.csv\", header=None)\n",
    "no_cyclone = pd.read_csv(\"shuffle_no_cyclone.csv\", header=None)\n",
    "\n",
    "np.nan_to_num(data, nan=0, copy=False)\n",
    "\n",
    "cyclone_occurances = cyclone_occurances.values[0]\n",
    "no_cyclone = no_cyclone.values[0]\n",
    "\n",
    "cut_cyclone = int(0.8 * len(cyclone_occurances))\n",
    "cut_no_cyclone = int(0.8 * len(no_cyclone))\n",
    "\n",
    "\n",
    "train_id = cyclone_occurances[:cut_cyclone].astype(int)\n",
    "train_id = np.append(train_id, no_cyclone[:cut_no_cyclone].astype(int))\n",
    "\n",
    "test_id = cyclone_occurances[cut_cyclone:-1].astype(int) \n",
    "test_id = np.append(test_id, no_cyclone[cut_no_cyclone:-1].astype(int))\n",
    "\n",
    "train_data = torch.tensor(data[:, :, train_id], dtype=torch.double)\n",
    "test_data = torch.tensor(data[:, :, test_id], dtype=torch.double)\n",
    "\n",
    "labels_train = torch.tensor(labels[train_id])\n",
    "labels_test = torch.tensor(labels[test_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eaaf49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21ec146e1c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[:, :, 41000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "410f631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def conv2d_size_out(size, kernel_size=5, stride=2):\n",
    "    \"\"\"\n",
    "    common use case:\n",
    "    cur_layer_img_w = conv2d_size_out(cur_layer_img_w, kernel_size, stride)\n",
    "    cur_layer_img_h = conv2d_size_out(cur_layer_img_h, kernel_size, stride)\n",
    "    to understand the shape for dense layer's input\n",
    "    \"\"\"\n",
    "    return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "\n",
    "def maxpool2d_size_out(size, kernel_size=2, stride=2):\n",
    "    return math.floor((size - (kernel_size - 1) - 1) / stride + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9104e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()        \n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=36,            \n",
    "                kernel_size=5,          \n",
    "                stride=2),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        \n",
    "        new_w = maxpool2d_size_out(conv2d_size_out(36, 5, 2), 2, 2)\n",
    "        new_h = maxpool2d_size_out(conv2d_size_out(69, 5, 2), 2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=36,              \n",
    "                out_channels=72,            \n",
    "                kernel_size=5,          \n",
    "                stride=2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )        \n",
    "        \n",
    "        new_w = maxpool2d_size_out(conv2d_size_out(new_w, 5, 2), 2, 2)\n",
    "        new_h = maxpool2d_size_out(conv2d_size_out(new_h, 5, 2), 2, 2)\n",
    "        linear_input_size = new_w * new_h * 72\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.lin = nn.Linear(linear_input_size, 1) \n",
    "        self.out = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)      \n",
    "        \n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.lin(x)\n",
    "        output = self.out(x)\n",
    "        return output, x    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6a6ce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "loss_func = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(cnn.parameters(), lr = 0.01)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "02352553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 91168/91168 [02:43<00:00, 559.00it/s]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "def train(num_epochs, cnn, train_data, labels_train):  \n",
    "    cnn.train()\n",
    "    \n",
    "    cnn = cnn.double()\n",
    "        \n",
    "    # Train the model\n",
    "    batch_size = 1\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        for i in tqdm(range(int(train_data.shape[2] / batch_size))):\n",
    "            \n",
    "            image = train_data[:, :, i]\n",
    "            label = labels_train[i]\n",
    "            \n",
    "            image = image.unsqueeze(0) \n",
    "            image = image.unsqueeze(0) \n",
    "            label = label.unsqueeze(0) \n",
    "            label = label.unsqueeze(0) \n",
    "            \n",
    "            # gives batch data, normalize x when iterate train_loader\n",
    "            b_x = Variable(image)   # batch x\n",
    "            b_y = Variable(label)   # batch y\n",
    "            output = cnn(b_x)[0]  \n",
    "            loss = loss_func(output, b_y)\n",
    "            # clear gradients for this training step   \n",
    "            optimizer.zero_grad()           \n",
    "            \n",
    "            # backpropagation, compute gradients \n",
    "            loss.backward()                # apply gradients             \n",
    "            optimizer.step()  \n",
    "        \n",
    "        pass\n",
    "    pass\n",
    "\n",
    "train(num_epochs, cnn, train_data, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db8c299b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 22792 test images: 0.49\n"
     ]
    }
   ],
   "source": [
    "def test(test_data, labels_test):\n",
    "    # Test the model\n",
    "    cnn.eval()    \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        tn = 0\n",
    "        for i in range(test_data.shape[2]):\n",
    "            image = test_data[:, :, i]\n",
    "            label = labels_test[i]\n",
    "            image = image.unsqueeze(0) \n",
    "            image = image.unsqueeze(0) \n",
    "            \n",
    "            test_output, last_layer = cnn(image)\n",
    "            pred_y = 0 if test_output[0] > 0.5 else 1\n",
    "            if (pred_y == label and label == 1):\n",
    "                tp += 1\n",
    "            elif (pred_y == label and label == 0):\n",
    "                tn += 1\n",
    "            elif (pred_y != label and label == 1):\n",
    "                fn += 1\n",
    "            elif (pred_y != label and label == 0):\n",
    "                fp += 1\n",
    "            pass\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (fp + tn)\n",
    "        balanced_accuracy = (sensitivity + specificity) / 2\n",
    "        print(f'Test Accuracy of the model on the {test_data.shape[2]} test images: %.2f' % balanced_accuracy)\n",
    "    \n",
    "    pass\n",
    "test(test_data, labels_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d16e234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
